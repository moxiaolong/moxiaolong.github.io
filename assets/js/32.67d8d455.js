(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{348:function(t,s,a){"use strict";a.r(s);var n=a(8),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("哈希表作为一种非常常用的数据结构，存在于各种编程语言中，它可以让我们保存"),s("strong",[t._v("键值对")]),t._v("数据，而且有着非常高的查找效率。 本文就以 go 语言中的 "),s("code",[t._v("map")]),t._v(" 为例子，讲述一下哈希表在 go 中的实现。\n")]),t._v(" "),s("blockquote",[s("p",[t._v("本文基于 go 1.19")])]),t._v(" "),s("h2",{attrs:{id:"哈希表基本操作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表基本操作"}},[t._v("#")]),t._v(" 哈希表基本操作")]),t._v(" "),s("p",[t._v("在开始之前，需要大概讲解一下哈希表这种数据结构，哈希表会预先在内存中分配一段比较大的内存，这段内存用在将来往里面写入数据的时候使用。 哈希表有点类似数组，都是一段连续的内存，但是我们往哈希表读写数据的时候不同于数组，数组的时候是"),s("strong",[t._v("直接通过下标访问")]),t._v("的， 而哈希表的读写需要先计算 "),s("code",[t._v("key")]),t._v(" 的哈希值，根据这个哈希值对哈希表长度取模得到 "),s("code",[t._v("key")]),t._v(" 对应的哈希表的下标，然后对哈希表这个下标进行读写操作。")]),t._v(" "),s("p",[t._v("对于哈希表有以下几种常见的操作：")]),t._v(" "),s("ol",[s("li",[t._v("写入：根据 "),s("code",[t._v("key")]),t._v(" 计算 "),s("code",[t._v("hash")]),t._v(" 值，对哈希表长度取模得到 "),s("code",[t._v("key")]),t._v(" 在内存中的地址，然后往这个地址写入数据。")]),t._v(" "),s("li",[t._v("读取：根据 "),s("code",[t._v("key")]),t._v(" 计算 "),s("code",[t._v("hash")]),t._v(" 值，对哈希表长度取模得到 "),s("code",[t._v("key")]),t._v(" 在内存中的地址，然后读取这个地址中的数据。")]),t._v(" "),s("li",[t._v("修改：根据 "),s("code",[t._v("key")]),t._v(" 计算 "),s("code",[t._v("hash")]),t._v(" 值，对哈希表长度取模得到 "),s("code",[t._v("key")]),t._v(" 在内存中的地址，然后修改这个内存地址里面的数据。")]),t._v(" "),s("li",[t._v("删除：根据 "),s("code",[t._v("key")]),t._v(" 计算 "),s("code",[t._v("hash")]),t._v(" 值，对哈希表长度取模得到 "),s("code",[t._v("key")]),t._v(" 在内存中的地址，然后清空保存这个 "),s("code",[t._v("key")]),t._v(" 的那一小块内存。")])]),t._v(" "),s("p",[t._v("注意：计算出的 "),s("code",[t._v("hash")]),t._v(" 值可能比分配的内存大小要大，所以才需要对其取模（"),s("code",[t._v("hash")]),t._v(" 值 / 哈希表长度 => "),s("code",[t._v("key")]),t._v(" 在哈希表的索引）， 保证计算出的 "),s("code",[t._v("hash")]),t._v(" 最终落到哈希表的内存范围之内。比如，"),s("code",[t._v("keyn")]),t._v(" 计算出来的哈希值为 "),s("code",[t._v("100")]),t._v("，但是我们的哈希表长度只有 "),s("code",[t._v("8")]),t._v("， 那么 "),s("code",[t._v("keyn")]),t._v(" 最终会落在哈希表中下标为 "),s("code",[t._v("2")]),t._v(" 的地方（"),s("code",[t._v("100 % 7 = 2")]),t._v("，下标是从 "),s("code",[t._v("0")]),t._v(" 开始的，所以这里是 "),s("code",[t._v("7")]),t._v("）")]),t._v(" "),s("h3",{attrs:{id:"哈希表的写入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表的写入"}},[t._v("#")]),t._v(" 哈希表的写入")]),t._v(" "),s("p",[t._v("假设我们现在要有一个长度为 8 的哈希表（下图左），我们有数据 "),s("code",[t._v('{"a": 1, "b": 2}')]),t._v(" 需要存入这个哈希表，存入之后的哈希表为下图右：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/1.webp",alt:"map_1_1.png"}})]),t._v(" "),s("p",[t._v("说明："),s("code",[t._v("hash(a) = 5")]),t._v("，计算 "),s("code",[t._v("a")]),t._v(" 的哈希值得到 "),s("code",[t._v("5")]),t._v("，所以将 "),s("code",[t._v("a:1")]),t._v(" 存入了哈希表中下标为 "),s("code",[t._v("5")]),t._v(" 的地址处。"),s("code",[t._v("b")]),t._v(" 同理。")]),t._v(" "),s("blockquote",[s("p",[t._v("注意：键值都会存储。")])]),t._v(" "),s("h3",{attrs:{id:"哈希表的读取"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表的读取"}},[t._v("#")]),t._v(" 哈希表的读取")]),t._v(" "),s("p",[t._v("从哈希表中读取 "),s("code",[t._v("key")]),t._v(" 为 "),s("code",[t._v("b")]),t._v(" 的键值对：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/2.webp",alt:"map_1_2.png"}})]),t._v(" "),s("h3",{attrs:{id:"哈希表的修改"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表的修改"}},[t._v("#")]),t._v(" 哈希表的修改")]),t._v(" "),s("p",[t._v("现在，我们需要将 "),s("code",[t._v("a")]),t._v(" 的值修改为 "),s("code",[t._v("3")]),t._v("，同样的，计算其 "),s("code",[t._v("hash")]),t._v(" 值，得到 "),s("code",[t._v("5")]),t._v("，然后将哈希表中 "),s("code",[t._v("5")]),t._v(" 这个下标的内存修改成 "),s("code",[t._v("3")]),t._v("：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/3.webp",alt:"map_1_3.png"}})]),t._v(" "),s("h3",{attrs:{id:"哈希表的删除"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表的删除"}},[t._v("#")]),t._v(" 哈希表的删除")]),t._v(" "),s("p",[t._v("假设要将哈希表中 "),s("code",[t._v("b")]),t._v(" 这个键删除，会先计算其 "),s("code",[t._v("hash")]),t._v(" 值，得到 "),s("code",[t._v("0")]),t._v("，然后将哈希表中 "),s("code",[t._v("0")]),t._v(" 这个下标的内存清空：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/4.webp",alt:"map_1_4.png"}})]),t._v(" "),s("h3",{attrs:{id:"哈希表的高效之处"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表的高效之处"}},[t._v("#")]),t._v(" 哈希表的高效之处")]),t._v(" "),s("p",[t._v("通过上面的分析，我们可以知道，哈希表的内存布局跟数组类似，但是哈希表的存储要通过计算 "),s("code",[t._v("key")]),t._v(" 的哈希值来得到其在哈希表中的索引，最后对这个索引的内存进行 CRUD 操作。这样一来，如果我们需要频繁的根据键查找其对应值的话，使用哈希表无疑会大大提高效率。相比之下，如果使用数组来存储，那么每次搜索都需要将整个数组遍历一次，效率非常低下。")]),t._v(" "),s("p",[t._v("比如下图，假设我们一个数组内存布局如下，那么在我们查找 "),s("code",[t._v("a:1")]),t._v(" 的时候，需要从数组的第一个元素开始遍历，每一个元素读取出来看看它的键是不是 "),s("code",[t._v("a")]),t._v("， 取到第 "),s("code",[t._v("6")]),t._v(" 个元素（下标 "),s("code",[t._v("5")]),t._v("）的时候，发现它的键是 "),s("code",[t._v("a")]),t._v("，然后取出对应的值 "),s("code",[t._v("1")]),t._v("。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/5.webp",alt:"map_1_5.png"}})]),t._v(" "),s("p",[t._v("在数组的元素个数少的时候，这种查找效率其实影响不大，但如果我们有上万个元素的时候，每次查找都要从第一个元素开始遍历，效率无疑会非常低。 相比之下，不管数据再怎么多，使用哈希表的方式，我们直接通过哈希算法计算一下就可以知道键保存到了哪个槽中。")]),t._v(" "),s("h2",{attrs:{id:"哈希冲突解决方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希冲突解决方法"}},[t._v("#")]),t._v(" 哈希冲突解决方法")]),t._v(" "),s("p",[t._v("在上一节中，我们的图将哈希表的每一个槽（"),s("code",[t._v("slot")]),t._v("，又或者叫 "),s("code",[t._v("cell")]),t._v("，都是同一个东西）都表示成只有一个元素了。 但在实际中，往往会出现计算出来的哈希值对哈希表长度取模后是相等的，也就是不同的 "),s("code",[t._v("key")]),t._v(" 会落到同一个槽中（这就是 "),s("strong",[t._v("哈希冲突")]),t._v("），")]),t._v(" "),s("p",[t._v("这种情况下，一个槽存放不下的话，有两种办法可以处理："),s("strong",[t._v("开放地址法")]),t._v("和"),s("strong",[t._v("链表法")]),t._v("。go 里面的 "),s("code",[t._v("map")]),t._v(" 使用的是"),s("strong",[t._v("链表法")]),t._v("， 具体来说，就是在 "),s("code",[t._v("hash")]),t._v(" 冲突的地方，建立一个链表来保存相同 "),s("code",[t._v("hash")]),t._v(" 值的 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("p",[t._v("这样一来，我们通过 "),s("code",[t._v("hash")]),t._v(" 算法计算出哈希值的时候，并不能唯一确定对应的值了，因为有可能两个 "),s("code",[t._v("key")]),t._v(" 经过哈希算法计算之后，得到的哈希值是一样的。 这种情况怎么办呢？很简单，因为虽然哈希值是一样的，但是它们的 "),s("code",[t._v("key")]),t._v(" 是不一样的，再比较一下 "),s("code",[t._v("key")]),t._v(" 就可以确定了。具体可以参考下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/6.webp",alt:"map_1_6.png"}})]),t._v(" "),s("p",[t._v("有哈希冲突的情况下，读取哈希表数据的过程：")]),t._v(" "),s("ul",[s("li",[t._v("计算 "),s("code",[t._v("c")]),t._v(" 的 "),s("code",[t._v("hash")]),t._v(" 值，得到 "),s("code",[t._v("0")]),t._v("，就是哈希表的索引")]),t._v(" "),s("li",[t._v("获取哈希表中地址 "),s("code",[t._v("0")]),t._v(" 上的数据，这会遍历冲突产生的链表")]),t._v(" "),s("li",[t._v("比较 "),s("code",[t._v("c")]),t._v(" 跟 "),s("code",[t._v("b")]),t._v("，不相等，继续比较链表下一个元素")]),t._v(" "),s("li",[t._v("比较 "),s("code",[t._v("c")]),t._v(" 跟 "),s("code",[t._v("c")]),t._v("，相等，返回 "),s("code",[t._v("3")])])]),t._v(" "),s("h2",{attrs:{id:"哈希扩容"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希扩容"}},[t._v("#")]),t._v(" 哈希扩容")]),t._v(" "),s("p",[t._v("go 里面 "),s("code",[t._v("map")]),t._v(" 扩容有两种方式："),s("strong",[t._v("增量扩容")]),t._v("和"),s("strong",[t._v("等量扩容")]),t._v("。")]),t._v(" "),s("h3",{attrs:{id:"哈希表总元素个数过多导致的扩容"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希表总元素个数过多导致的扩容"}},[t._v("#")]),t._v(" 哈希表总元素个数过多导致的扩容")]),t._v(" "),s("p",[t._v("这种扩容方式也叫"),s("strong",[t._v("增量扩容")]),t._v("。")]),t._v(" "),s("p",[t._v("我们在上面说过了，其实哈希表的内存布局跟数组类似，都是先分配一段连续的内存。然后在哈希冲突的时候，对于冲突的 "),s("code",[t._v("key")]),t._v(" 建立一个链表来保存。 这样就会出现一种情况，在链表中存在很多冲突的键，这样一来，在查找冲突 "),s("code",[t._v("key")]),t._v(" 的时候，需要在这一堆冲突的 "),s("code",[t._v("key")]),t._v(" 中进行查找，这个查找类似数组的查找，效率较低。")]),t._v(" "),s("p",[t._v("为了避免这种情况的出现，一般的哈希表设计会在元素个数总数超过一定数量的时候，对哈希表进行扩容， 这样一来，那些哈希冲突的键就可以相对均匀地分布在哈希表中，从而避免了很多哈希冲突情况下导致的查找效率低下的问题。")]),t._v(" "),s("blockquote",[s("p",[t._v("扩容之后的容量为原来容量的 2 倍。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/7.webp",alt:"map_1_7.png"}})]),t._v(" "),s("h4",{attrs:{id:"go-map-的负载因子"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#go-map-的负载因子"}},[t._v("#")]),t._v(" go map 的负载因子")]),t._v(" "),s("p",[t._v("在 go 中，"),s("code",[t._v("map")]),t._v(" 在实际存储的元素数量超过 "),s("code",[t._v("map")]),t._v(" 里 "),s("code",[t._v("bucket")]),t._v(" 总数量的 "),s("code",[t._v("6.5")]),t._v(" 倍的时候（也就是平均每个 "),s("code",[t._v("bucket")]),t._v(" 中的元素个数大于 "),s("code",[t._v("6.5")]),t._v(" 的时候），会进行扩容， 这个 "),s("code",[t._v("6.5")]),t._v(" 是实现 "),s("code",[t._v("map")]),t._v(" 的那个开发者经过实验计算出来的比较合适的数，这个 "),s("code",[t._v("6.5")]),t._v(" 被称为负载因子。")]),t._v(" "),s("p",[t._v("为什么负载因子是 "),s("code",[t._v("6.5")]),t._v(" 呢，在 go 的 "),s("code",[t._v("map")]),t._v(" 源码中有相关的说明：")]),t._v(" "),s("p",[s("strong",[t._v("选择负载因子，如果太大，会有很多溢出桶，太小，则会浪费很多空间")]),t._v("。 我编写了一个简单的程序来检查不同负载的一些统计数据:（64位、8字节 key 和元素）")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("loadFactor")]),t._v(" "),s("th",[t._v("%overflow")]),t._v(" "),s("th",[t._v("bytes/entry")]),t._v(" "),s("th",[t._v("hitprobe")]),t._v(" "),s("th",[t._v("missprobe")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("4.00")]),t._v(" "),s("td",[t._v("2.13")]),t._v(" "),s("td",[t._v("20.77")]),t._v(" "),s("td",[t._v("3.00")]),t._v(" "),s("td",[t._v("4.00")])]),t._v(" "),s("tr",[s("td",[t._v("4.50")]),t._v(" "),s("td",[t._v("4.05")]),t._v(" "),s("td",[t._v("17.30")]),t._v(" "),s("td",[t._v("3.25")]),t._v(" "),s("td",[t._v("4.50")])]),t._v(" "),s("tr",[s("td",[t._v("5.00")]),t._v(" "),s("td",[t._v("6.85")]),t._v(" "),s("td",[t._v("14.77")]),t._v(" "),s("td",[t._v("3.50")]),t._v(" "),s("td",[t._v("5.00")])]),t._v(" "),s("tr",[s("td",[t._v("5.50")]),t._v(" "),s("td",[t._v("10.55")]),t._v(" "),s("td",[t._v("12.94")]),t._v(" "),s("td",[t._v("3.75")]),t._v(" "),s("td",[t._v("5.50")])]),t._v(" "),s("tr",[s("td",[t._v("6.00")]),t._v(" "),s("td",[t._v("15.27")]),t._v(" "),s("td",[t._v("11.67")]),t._v(" "),s("td",[t._v("4.00")]),t._v(" "),s("td",[t._v("6.00")])]),t._v(" "),s("tr",[s("td",[t._v("6.50")]),t._v(" "),s("td",[t._v("20.90")]),t._v(" "),s("td",[t._v("10.79")]),t._v(" "),s("td",[t._v("4.25")]),t._v(" "),s("td",[t._v("6.50")])]),t._v(" "),s("tr",[s("td",[t._v("7.00")]),t._v(" "),s("td",[t._v("27.14")]),t._v(" "),s("td",[t._v("10.15")]),t._v(" "),s("td",[t._v("4.50")]),t._v(" "),s("td",[t._v("7.00")])]),t._v(" "),s("tr",[s("td",[t._v("7.50")]),t._v(" "),s("td",[t._v("34.03")]),t._v(" "),s("td",[t._v("9.73")]),t._v(" "),s("td",[t._v("4.75")]),t._v(" "),s("td",[t._v("7.50")])]),t._v(" "),s("tr",[s("td",[t._v("8.00")]),t._v(" "),s("td",[t._v("41.10")]),t._v(" "),s("td",[t._v("9.40")]),t._v(" "),s("td",[t._v("5.00")]),t._v(" "),s("td",[t._v("8.00")])])])]),t._v(" "),s("p",[t._v("列说明：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("%overflow")]),t._v(": 具有溢出桶的桶的百分比")]),t._v(" "),s("li",[s("code",[t._v("bytes/entry")]),t._v(": 每个 key/elem 对使用的开销字节")]),t._v(" "),s("li",[s("code",[t._v("hitprobe")]),t._v(": 查找当前 key 时要检查的条目数")]),t._v(" "),s("li",[s("code",[t._v("missprobe")]),t._v(": 查找缺少的 key 时要检查的条目数")])]),t._v(" "),s("h3",{attrs:{id:"哈希冲突链上元素太少导致的扩容"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哈希冲突链上元素太少导致的扩容"}},[t._v("#")]),t._v(" 哈希冲突链上元素太少导致的扩容")]),t._v(" "),s("p",[t._v("这种扩容方式也叫"),s("strong",[t._v("等量扩容")]),t._v("。")]),t._v(" "),s("p",[t._v("我们知道，在哈希冲突的时候，会建立链表来保存键冲突的元素，但是我们删除那些哈希冲突的键的时候，并不会对删除元素的内存进行释放， 如果每次删除都释放的话，在我们频繁插入跟删除的时候，效率就非常低下了。 因为插入一个元素就分配内存，删除一个元素就释放内存（分配内存和释放内存都是相对耗时的操作）。 而这样的结果是，保存冲突键的链表上，有很多空的元素，这样就会导致冲突的时候，查找键的效率降低，因为要遍历很多空的键。")]),t._v(" "),s("p",[t._v("删除的时候不释放，那什么时候会释放呢？哈希冲突的元素很多都被删除的时候，在 go 里面，"),s("code",[t._v("map")]),t._v(" 会判断就算没有超过负载因子的情况下， 如果冲突链表占用的空间过大的话，也会进行扩容。但这里说的扩容其实并不是真正意义上的扩容，只是 "),s("code",[t._v("map")]),t._v(" 的实现里面，使用的函数是同一个函数。")]),t._v(" "),s("p",[t._v("具体实现方式是，分配跟原哈希表相同大小的空间，然后将旧哈希表的数据迁移到新的哈希表。 这样迁移之后，对于哈希冲突链表上的那些元素，只会迁移非空的元素，最终结果就是，扩容之后，哈希冲突链表上的元素更加紧凑，在查找冲突的键的时候会更加高效。")]),t._v(" "),s("blockquote",[s("p",[t._v("虽然哈希表的总容量没变，但是数据分布更加紧凑了，省去了遍历空元素的时间。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/8.webp",alt:"map_1_8.png"}})]),t._v(" "),s("h2",{attrs:{id:"go-map-概述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#go-map-概述"}},[t._v("#")]),t._v(" go map 概述")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("map")]),t._v(" 只是一个哈希表。数据被排列成一组 "),s("code",[t._v("bucket")]),t._v("。")]),t._v(" "),s("li",[t._v("每个 "),s("code",[t._v("bucket")]),t._v(" 最多包含 "),s("code",[t._v("8")]),t._v(" 个 "),s("code",[t._v("键/值")]),t._v(" 对。")]),t._v(" "),s("li",[t._v("哈希值的低位字节位用于选择 "),s("code",[t._v("bucket")]),t._v("。")]),t._v(" "),s("li",[t._v("每个 "),s("code",[t._v("bucket")]),t._v(" 包含每个哈希的几个高位字节位("),s("code",[t._v("tophash")]),t._v(")，以区分单个桶中的条目。")]),t._v(" "),s("li",[t._v("如果超过 "),s("code",[t._v("8")]),t._v(" 个 "),s("code",[t._v("key")]),t._v(" 哈希到同一个桶，我们将额外的桶以链表的方式起来。（解决哈希冲突，链表法）")]),t._v(" "),s("li",[t._v("当哈希表扩容时，我们会分配一个两倍大的新 "),s("code",[t._v("bucket")]),t._v(" 数组。然后 "),s("code",[t._v("bucket")]),t._v(" 从旧 "),s("code",[t._v("bucket")]),t._v(" 数组增量复制到新 "),s("code",[t._v("bucket")]),t._v(" 数组。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 迭代器遍历 "),s("code",[t._v("bucket")]),t._v(" 数组，并按遍历顺序返回键（遍历完普通桶之后，遍历溢出桶）。")]),t._v(" "),s("li",[t._v("为了保持迭代语义，我们永远不会在它们的桶中移动键（"),s("code",[t._v("bucket")]),t._v(" 内键的顺序在扩容的时候不变。如果改变了桶内键的相对顺序，键可能会返回 0 或 2 次）。")]),t._v(" "),s("li",[t._v("在扩容哈希表时，迭代器仍在旧的桶中迭代，并且必须检查新桶，检查正在迭代的 "),s("code",[t._v("bucket")]),t._v(" 是否已经被迁移到新桶。")])]),t._v(" "),s("h2",{attrs:{id:"go-map-的整体模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#go-map-的整体模型"}},[t._v("#")]),t._v(" go map 的整体模型")]),t._v(" "),s("p",[t._v("上面讲了哈希表的基本设计思路，接下来就要开始讲 go 里面 "),s("code",[t._v("map")]),t._v(" 的设计与实现了。大体上其实就是上面说的样子，但是有下面几个不一样的地方：")]),t._v(" "),s("blockquote",[s("p",[t._v("下文的 "),s("code",[t._v("bucket")]),t._v(" 和 "),s("code",[t._v("bmap")]),t._v(' 都是指的 "桶"。')])]),t._v(" "),s("ul",[s("li",[t._v("go "),s("code",[t._v("map")]),t._v(" 里面存储数据的地方是 "),s("code",[t._v("bucket")]),t._v("（桶），一个 "),s("code",[t._v("bucket")]),t._v(" 可以存储 "),s("code",[t._v("8")]),t._v(" 个元素，也就是说哈希冲突的时候还是会在同一个 "),s("code",[t._v("bucket")]),t._v(" 中先存储。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("bucket")]),t._v(" 也存放不下冲突的元素了，那么会新建另外一个桶（叫做溢出桶），旧的 "),s("code",[t._v("bucket")]),t._v(" 记录这个新桶的指针，旧的 "),s("code",[t._v("bucket")]),t._v(" 存放不下的元素，会存放到这个溢出桶中。")]),t._v(" "),s("li",[t._v("如果溢出桶还是存放不下，那么再新建一个溢出桶，链接到上一个溢出桶中。")])]),t._v(" "),s("p",[t._v("也就是说，在 go 的 "),s("code",[t._v("map")]),t._v(" 实现中，哈希计算出来的值决定了 "),s("code",[t._v("key")]),t._v(" 应该存放在哪一个 "),s("code",[t._v("bucket")]),t._v(" 中。")]),t._v(" "),s("p",[t._v("go "),s("code",[t._v("map")]),t._v(" 的整体结构如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/9.webp",alt:"map_2_1.png"}})]),t._v(" "),s("ul",[s("li",[s("code",[t._v("buckets")]),t._v(" 记录了保存 "),s("code",[t._v("map")]),t._v(" 数据的所有 "),s("code",[t._v("bucket")]),t._v("（这种下文统一称为"),s("strong",[t._v("普通桶")]),t._v("），go 中使用 "),s("code",[t._v("bmap")]),t._v(" 这个结构体来表示 "),s("code",[t._v("bucket")]),t._v("，溢出桶也是使用 "),s("code",[t._v("bmap")]),t._v(" 结构体表示。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("bucket")]),t._v("（普通桶）哈希冲突太多导致存放不下，会新建一个 "),s("code",[t._v("bucket")]),t._v("，在原来的 "),s("code",[t._v("bucket")]),t._v(" 上会有一个指针记录新建 "),s("code",[t._v("bucket")]),t._v(" 的地址，这个新 "),s("code",[t._v("bucket")]),t._v(" 下文统一称为"),s("strong",[t._v("溢出桶")]),t._v("。")]),t._v(" "),s("li",[t._v("在创建 "),s("code",[t._v("map")]),t._v(" 的时候，如果我们指定的容量比较大（"),s("code",[t._v("B >= 4")]),t._v(" 的时候），那么会预创建一个溢出桶。")])]),t._v(" "),s("p",[t._v("也就是说，go 中解决哈希冲突的链表法，链表上的每一个元素是一个 "),s("code",[t._v("bucket")]),t._v("。go "),s("code",[t._v("map")]),t._v(" 的实现里面，"),s("strong",[t._v("一个 "),s("code",[t._v("bucket")]),t._v(" 可以存放 "),s("code",[t._v("8")]),t._v(" 个键值对")]),t._v("。")]),t._v(" "),s("p",[t._v("上面的 "),s("code",[t._v("bmap")]),t._v(" 的数据结构如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/10.webp",alt:"map_2_2.png"}})]),t._v(" "),s("ul",[s("li",[s("code",[t._v("bmap")]),t._v(" 就是 "),s("code",[t._v("bucket")]),t._v("（桶），不管是普通的桶还是溢出的桶，都是使用 "),s("code",[t._v("bmap")]),t._v(" 结构体表示。")]),t._v(" "),s("li",[s("code",[t._v("bmap")]),t._v(" 中存储数据的方式有点特别，它先存储了 "),s("code",[t._v("8")]),t._v(" 个 "),s("code",[t._v("tophash")]),t._v(" 值，一个 "),s("code",[t._v("tophash")]),t._v(" 的大小为 1 个字节，每一个 "),s("code",[t._v("tophash")]),t._v(" 记录的是 "),s("code",[t._v("bmap")]),t._v(" 中每一个元素的哈希值的最高的 8 bit。")]),t._v(" "),s("li",[t._v("接下来是 "),s("code",[t._v("bmap")]),t._v(" 存储的 8 个元素的 "),s("code",[t._v("key")]),t._v("，在 8 个 "),s("code",[t._v("key")]),t._v(" 之后是 8 个 "),s("code",[t._v("bmap")]),t._v(" 存储的值。我们会发现 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 的存储是分开的，而不是 "),s("code",[t._v("key/value")]),t._v("、"),s("code",[t._v("key/value")]),t._v(" 这种方式。go 中这种分开存储的方式有一个好处是可以减少内存对齐的开销，从而更省内存。")]),t._v(" "),s("li",[t._v("最后是 "),s("code",[t._v("overflow")]),t._v("（溢出桶），如果 "),s("code",[t._v("bmap")]),t._v(" 存满了，那就会新建一个溢出桶来保存新的数据，通过在旧的 "),s("code",[t._v("bmap")]),t._v(" 上记录指针来记录溢出桶。")])]),t._v(" "),s("p",[s("code",[t._v("tophash")]),t._v(" 的作用是，在哈希冲突的时候，在 "),s("code",[t._v("bucket")]),t._v(" 内进行查找的时候，是需要在 "),s("code",[t._v("bucket")]),t._v(" 内从第一个元素遍历到最后一个元素来查找的。 如果 "),s("code",[t._v("key")]),t._v(" 太大，直接比较 "),s("code",[t._v("key")]),t._v(" 的话效率会比较低下，通过记录哈希值的高 8 位，我们就可以在 "),s("code",[t._v("buckeet")]),t._v(" 内查找的时候，先比较哈希值的 前 8 位，这样一来，"),s("code",[t._v("map")]),t._v(" 的效率受到 "),s("code",[t._v("key")]),t._v(" 大小的影响就会比较小。当然哈希值的高 8 位有可能相同，在这种情况下，我们再比较一下 "),s("code",[t._v("key")]),t._v(" 本身 就可以确定 "),s("code",[t._v("bucket")]),t._v(" 的那个槽（"),s("code",[t._v("slot")]),t._v("/"),s("code",[t._v("cell")]),t._v("）是否是我们正在查找的那一个 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("h2",{attrs:{id:"go-map-相关数据结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#go-map-相关数据结构"}},[t._v("#")]),t._v(" go map 相关数据结构")]),t._v(" "),s("p",[t._v("我们大部分内容是跟下面两个结构体打交道：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("hmap")]),t._v(": "),s("code",[t._v("map")]),t._v(" 的数据结构，包含了 "),s("code",[t._v("bucket")]),t._v(" 的指针、"),s("code",[t._v("bucket")]),t._v(" 的数量、键值对的数量等信息。")]),t._v(" "),s("li",[s("code",[t._v("bmap")]),t._v(": 桶，存储 "),s("code",[t._v("key/value")]),t._v(" 的地方")])]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// go map 数据结构")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" hmap "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   count     "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v("            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 的元素数量。调用 len(map) 的时候返回此值")]),t._v("\n   flags     "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 标记：iterator/oldIterator/hashWriting/sameSizeGrow")]),t._v("\n   B         "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指示了当前哈希表持有的 buckets 的数量（2^B 是 bucket 的数量）")]),t._v("\n   noverflow "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint16")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶的数量")]),t._v("\n   hash0     "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint32")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 哈希种子，计算 key 的哈希的时候会传入哈希函数")]),t._v("\n   buckets   unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指向 buckets 的数组，大小为 2^B。 如果元素个数为 0 则为 nil。")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 哈希表扩容的时候记录 buckets 字段。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 增量扩容时，oldbuckets 的长度是 buckets 的一半。")]),t._v("\n   oldbuckets unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer\n\n   nevacuate "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指示扩容进度，小于此地址的 buckets 完成迁移")]),t._v("\n   extra     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("mapextra "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 可选字段")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mapextra 包含并非在所有 map 上都存在的字段。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 下面 mapextra 注释是原文的翻译（看完了 map 的全部源码也还不是很懂这个结构体的作用，除了 nextOverflow 字段）。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" mapextra "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 key 和 elem 都不包含指针并且是内联的，那么我们将 bucket type 标记为不包含指针。这避免了扫描此类 map。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但是，bmap.overflow 是一个指针。 为了让溢出桶保持活动状态，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 我们将指向所有溢出桶的指针存储在 hmap.extra.overflow 和 hmap.extra.oldoverflow 中。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// overflow 和 oldoverflow 仅在 key 和 elem 不包含指针时使用。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// overflow 包含 hmap.buckets 的溢出桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// oldoverflow 包含 hmap.oldbuckets 的溢出桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 间接允许在 hiter 中存储指向切片的指针。")]),t._v("\n   overflow    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n   oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// nextOverflow 持有指向空闲溢出桶的指针。")]),t._v("\n   nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// go map 中的 bucket 结构体（实际保存 key/value 的地方）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" bmap "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 通常包含此 bucket 中每个键的哈希值的最高的 8 位（1 字节）。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 tophash[0] ＜ minTopHash，则 tophash[0] 为桶已迁移状态。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这是一个长度为 8 的数组，因为一个 bucket 只能存储 8 个元素。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 存储的是每一个元素的键的哈希的高 8 位。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（通过比较不同键的哈希的高 8 位可以提高 bucket 内的查找性能，因为键可能很大）")]),t._v("\n   tophash "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("\n   \n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 然后是 8 个键，然后是 8 个值。（这里的 8 是代码写死的）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意：将所有键放在在一起，然后将所有值放在一起使代码比交替的 key/elem/key/elem/… 复杂一些，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但它允许我们消除填充（减少内存对齐导致的内存浪费），例如 map[int64]int8，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这种如果使用 key/elem 的方式存储则需要浪费几个字节用来对齐。")]),t._v("\n   keys "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("keytype "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 8 个键")]),t._v("\n   values "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("valuetype "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 8 个值")]),t._v("\n   overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指向溢出桶的指针")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br")])]),s("p",[t._v("对于 "),s("code",[t._v("map")]),t._v(" 的数据结构，需要特别说明的是，"),s("code",[t._v("bmap")]),t._v(" 的源码中实际只包含了 "),s("code",[t._v("tophash")]),t._v(" 字段，而后面的三个字段 "),s("code",[t._v("keys/values/overflow")]),t._v(" 都是在编译期间动态添加的。这是因为 "),s("code",[t._v("map")]),t._v(" 中可能存储不同类型的键值对，所以键值对占据的内存空间大小只能在编译时进行推导。 这样一来，最终的结果是，我们在 "),s("code",[t._v("map")]),t._v(" 的源码中，访问 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 的时候都需要通过 "),s("code",[t._v("bmap")]),t._v(" 的首地址加上偏移量来进行访问的。")]),t._v(" "),s("p",[t._v("比如获取 "),s("code",[t._v("bucket")]),t._v(" 中第 "),s("code",[t._v("i")]),t._v(" 个 "),s("code",[t._v("key")]),t._v(" 的方式：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("这行代码中，"),s("code",[t._v("add")]),t._v(" 是做指针加法运算的函数，具体来说就是第一个参数的地址加上第二个参数（偏移量），得到一个我们想要的指针。 "),s("code",[t._v("dataOffset")]),t._v(" 代表了 "),s("code",[t._v("bmap")]),t._v(" 的 "),s("code",[t._v("keys")]),t._v(" 第一个元素的偏移量，"),s("code",[t._v("i")]),t._v(" 代表了我们想要获取的 "),s("code",[t._v("key")]),t._v(" 在 "),s("code",[t._v("keys")]),t._v(" 中的索引：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/11.webp",alt:"map_2_3.png"}})]),t._v(" "),s("p",[t._v("这样一来，我们就可以通过 "),s("code",[t._v("k")]),t._v(" 这个指针来访问 "),s("code",[t._v("bucket")]),t._v(" 中的 "),s("code",[t._v("key")]),t._v(" 了。同样的，要访问 "),s("code",[t._v("value")]),t._v(" 的方式也是类似的， 只要将 "),s("code",[t._v("dataOffset + i * uintptr(t.keysize)")]),t._v(" 替换成 "),s("code",[t._v("dataOffset + bucketCnt * uintptr(t.keysize)")]),t._v(" 即可。")]),t._v(" "),s("blockquote",[s("p",[t._v("这种方式虽然不太优雅，但是在性能上可以达到最优。")])]),t._v(" "),s("h2",{attrs:{id:"bmap-桶-源码剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bmap-桶-源码剖析"}},[t._v("#")]),t._v(" bmap（桶）源码剖析")]),t._v(" "),s("p",[s("code",[t._v("bmap")]),t._v(" 就是保存键值对的地方，但是它本身的方法并不多：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 是否已经完成迁移")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 是 bucket 的指针")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuated")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" emptyOne "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" minTopHash\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取 b 的溢出桶")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bmap 数据结构的最后一个指针就是指向溢出桶的指针")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("goarch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PtrSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 设置 b 的溢出桶")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bmap 数据结构的最后一个指针指向溢出桶")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setoverflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ovf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("goarch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PtrSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ovf\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取 b 中保存 keys 的指针（指向了桶内的第一个 key）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("keys")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br")])]),s("p",[t._v("在 "),s("code",[t._v("ev")]),t._v(" 中用到了两个常量，在 "),s("code",[t._v("bucket")]),t._v(" 的 "),s("code",[t._v("tophash")]),t._v(" 里面，会通过下面几个标志来记录桶里面槽的状态：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个 cell 是空的，并且在更高的索引或溢出处没有更多的非空 cell。")]),t._v("\nemptyRest "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个 cell 是空的")]),t._v("\nemptyOne "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key/elem 有效。 entry 已被迁移到较大的哈希表的前半部分（扩容了）。")]),t._v("\nevacuatedX "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 同上，但迁移到大的哈希表的后半部分（扩容了）。")]),t._v("\nevacuatedY "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// cell 是空的，bucket 已经被迁移了")]),t._v("\nevacuatedEmpty "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正常填充单元格的最小 tophash。")]),t._v("\nminTopHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br")])]),s("p",[t._v("为了跟正常的 "),s("code",[t._v("tophash")]),t._v(" 区分开来，如果计算出来的 "),s("code",[t._v("tophash")]),t._v(" 小于 "),s("code",[t._v("minTopHash")]),t._v("，会将计算出来的 "),s("code",[t._v("tophash")]),t._v(" 加上 "),s("code",[t._v("minTopHash")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 计算 hash 的 tophash 值。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这是一个字节的大小的。（hash 最高的 8 位）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tophash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// top 本质上就是 hash 的前面 8 个字节（goarch.PtrSize*8 - 8，左移位数：指针的字节大小 - 8 字节）")]),t._v("\n   top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("goarch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PtrSize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" minTopHash "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" minTopHash\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" top\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br")])]),s("p",[t._v("这样一来，"),s("strong",[t._v("通过 "),s("code",[t._v("tophash")]),t._v(" 这一个字节就可以记录桶里面槽的状态了，非常节省空间。")])]),t._v(" "),s("h2",{attrs:{id:"map-的创建的实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-的创建的实现"}},[t._v("#")]),t._v(" map 的创建的实现")]),t._v(" "),s("p",[t._v("我们已经了解了哈希表的基本工作机制了，现在就让我们来深入了解一下 go 里 "),s("code",[t._v("map")]),t._v(" 的实现，先是 "),s("code",[t._v("map")]),t._v(" 的创建， "),s("code",[t._v("map")]),t._v(" 的创建是通过 "),s("code",[t._v("makemap()")]),t._v(" 函数实现的（对应我们写的代码是 "),s("code",[t._v("make(map[int]int, 10)")]),t._v("），"),s("code",[t._v("map")]),t._v(" 的创建步骤如下：")]),t._v(" "),s("ol",[s("li",[t._v("计算 "),s("code",[t._v("map")]),t._v(" 所需内存，判断是否在一个合理范围之内。")]),t._v(" "),s("li",[t._v("使用 "),s("code",[t._v("new")]),t._v(" 初始化 "),s("code",[t._v("hmap")]),t._v(" 结构体。")]),t._v(" "),s("li",[t._v("生成随机哈希种子。")]),t._v(" "),s("li",[t._v("计算出一个最小的 "),s("code",[t._v("B")]),t._v("，也就是根据用户传递给 "),s("code",[t._v("make")]),t._v(" 的第二个参数算出一个最小的 "),s("code",[t._v("B")]),t._v(" 的值，最终桶的数量为 "),s("code",[t._v("2^B")]),t._v(" 个。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("B")]),t._v(" 大于 "),s("code",[t._v("0")]),t._v("，则给哈希表的 "),s("code",[t._v("buckets")]),t._v(" 分配内存。")]),t._v(" "),s("li",[t._v("最后，返回新创建好的 "),s("code",[t._v("hmap")]),t._v("。")])]),t._v(" "),s("p",[t._v("下文在寻址过程中，大量使用了指针的运算，所以如果对 "),s("code",[t._v("unsafe.Pointer")]),t._v(" 比较熟悉的话，看起来会比较轻松，如果不熟悉也没关系，可以看看我另外一篇文章《深入理解 go unsafe》。")]),t._v(" "),s("h3",{attrs:{id:"makemap-实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#makemap-实现"}},[t._v("#")]),t._v(" makemap 实现")]),t._v(" "),s("p",[s("code",[t._v("makemap")]),t._v(" 具体源码如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// makemap 是 make(map[k]v, hint) 的实现，创建一个 map。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果编译器可以确定 map 或者第一个 bucket 可以在栈上创建，h 和/或 bucket 可能为 non-nil。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 h != nil，map 可以直接在 h 中创建。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 h.buckets != nil，buckets 指针指向的那个元素可以作为第一个 bucket。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("makemap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hint "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算所需要的内存大小")]),t._v("\n   mem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" math"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("MulUintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果溢出或者超出最大分配内存，则设置 hint = 0；")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这样的话，B 也会等于 0；")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 则最终的 map 只会有一个 bucket（2^B = 1）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" mem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" maxAlloc "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      hint "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 初始化 hmap（分配 hmap 结构体本身所需要的内存）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("new")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 生成一个随机的哈希种子")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastrand")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 根据传入的 hint，计算出需要的最小桶数量。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 实际上是计算 B 的大小，桶的数量都是运行时通过 2^B 计算的。")]),t._v("\n   B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 hint 导致超过了负载因子，则将 B 加 1，一直加到小于负载因子。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 简单来说就是：hint / (2^B) > 负载因子，也就是 hint 个键值对放到所有桶中，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 每个桶中元素数量大于负载因子（6.5）的时候，则将 B 加 1。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注：map 扩容的时候也是这个判断标准。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" B\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 分配初始哈希表。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 B==0，则稍后（在mapassign中）延迟分配桶字段。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 若 hint 较大，则清零此内存可能需要一段时间。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 初始化 buckets（分配 buckets 所需要的内存）")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("makeBucketArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 hint 比较大，则会预先分配溢出桶，记录到 extra 字段中。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("new")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mapextra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nextOverflow\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" h\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br")])]),s("h3",{attrs:{id:"overloadfactor-实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#overloadfactor-实现"}},[t._v("#")]),t._v(" overLoadFactor 实现")]),t._v(" "),s("p",[t._v("这里面有一个比较重要的函数，那就是 "),s("code",[t._v("overLoadFactor")]),t._v("，这个函数用来判断某一个数量是否超过 "),s("code",[t._v("map")]),t._v(" 的负载因子，如果超过，那就需要扩容了：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// overLoadFactor 报告放置在 2^B 个桶中的键值对数量是否超过负载因子。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" loadFactorNum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketShift")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("loadFactorDen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("ul",[s("li",[s("code",[t._v("count > bucketCnt")]),t._v("，前半部分判断很简单，就是判断数量一个桶能不能放得下。一个桶就能装下所有数据的话，根本就不用计算了，肯定没超过负载因子。")]),t._v(" "),s("li",[t._v("后半部分判断翻译过来是："),s("code",[t._v("桶数量 * 负载因子(6.5) < 总键值对数量")]),t._v("，意味着平均每个桶存储的元素个数大于 "),s("code",[t._v("6.5")]),t._v(" 了，也就是说超过了负载因子了。")]),t._v(" "),s("li",[t._v("在其他函数中，"),s("strong",[t._v("判断是否超过负载因子的时候都是使用上面这个函数")]),t._v("。")]),t._v(" "),s("li",[s("code",[t._v("loadFactorNum")]),t._v(" 和 "),s("code",[t._v("loadFactorDen")]),t._v(" 是预定义的变量，它们相除就是负载因子 "),s("code",[t._v("6.5")]),t._v("。")]),t._v(" "),s("li",[s("code",[t._v("bucketShift(B)")]),t._v(" 很简单，就是 "),s("code",[t._v("2^B")]),t._v("。")])]),t._v(" "),s("h3",{attrs:{id:"makebucketarray-实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#makebucketarray-实现"}},[t._v("#")]),t._v(" makeBucketArray 实现")]),t._v(" "),s("p",[t._v("在创建 "),s("code",[t._v("map")]),t._v(" 的时候，使用了 "),s("code",[t._v("makeBucketArray")]),t._v(" 来给 "),s("code",[t._v("map")]),t._v(" 的桶分配内存，"),s("code",[t._v("makeBucketArray")]),t._v(" 实现步骤如下：")]),t._v(" "),s("ol",[s("li",[t._v("如果判断到 "),s("code",[t._v("B >= 4")]),t._v("，也就是初始化时需要分配的桶数量大于等于 "),s("code",[t._v("2^4 = 16")]),t._v(" 的时候，则会预先分配溢出桶，分配的溢出桶个数为 "),s("code",[t._v("2^(b-4)")]),t._v(" 个。")]),t._v(" "),s("li",[t._v("接着，给 "),s("code",[t._v("map")]),t._v(" 的桶（"),s("code",[t._v("buckets")]),t._v(" 字段）分配内存（包含了普通桶和溢出桶，普通桶和溢出桶的内存一次性分配，溢出桶的内存在普通桶后面）。")]),t._v(" "),s("li",[t._v("最后，判断到需要分配溢出桶的话（"),s("code",[t._v("B >= 4")]),t._v("），则将溢出桶的指针写入到最后一个普通桶的 "),s("code",[t._v("overflow")]),t._v(" 字段。")])]),t._v(" "),s("p",[t._v("分配 "),s("code",[t._v("buckets")]),t._v(" 内存的两种情况：")]),t._v(" "),s("ol",[s("li",[t._v("如果 "),s("code",[t._v("B < 4")]),t._v("，那么分配内存的过程很简单，就是分配 "),s("code",[t._v("buckets")]),t._v(" 所需要的内存，也就是分配普通桶所需要的内存就足够了，如下图：")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/12.webp",alt:"map_3_1.png"}})]),t._v(" "),s("ol",[s("li",[t._v("如果 "),s("code",[t._v("B >= 4")]),t._v("，那么分配内存的过程就相对复杂，会预先分配一部分溢出桶。在后面需要创建溢出桶的时候，就会先使用这时候创建的溢出桶，而不是直接新建，如下图：")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/13.webp",alt:"map_3_2.png"}})]),t._v(" "),s("p",[t._v("说明：")]),t._v(" "),s("ul",[s("li",[t._v("分配 "),s("code",[t._v("buckets")]),t._v(" 所需要的内存的时候，会分配一部分溢出桶所需要的内存，普通桶和溢出桶的内存是连续的，分配给溢出桶的内存就在普通桶的后面。")]),t._v(" "),s("li",[t._v("在 "),s("code",[t._v("makemap")]),t._v(" 中会新建 "),s("code",[t._v("mapextra")]),t._v(" 结构体，用 "),s("code",[t._v("nextOverflow")]),t._v(" 字段来保存溢出桶的指针，指向第一个溢出桶的位置。")]),t._v(" "),s("li",[t._v("最后一个溢出桶的 "),s("code",[t._v("overflow")]),t._v(" 指针（指向溢出桶的指针），指向了 "),s("code",[t._v("buckets")]),t._v(" 入口，这里并不是说将第一个普通桶作为最后一个溢出桶的溢出桶，而是一个标记作用。因为前面的溢出桶的 "),s("code",[t._v("overflow")]),t._v(" 字段都是 "),s("code",[t._v("nil")]),t._v("，而最后一个溢出桶的 "),s("code",[t._v("overflow")]),t._v(" 不是 "),s("code",[t._v("nil")]),t._v("，这样一来，我们通过判断溢出桶的 "),s("code",[t._v("overflow")]),t._v(" 是否为 "),s("code",[t._v("nil")]),t._v(" 就可以知道是否是最后一个溢出桶。如果是最后一个溢出桶，那么将 "),s("code",[t._v("map")]),t._v(" 里面的 "),s("code",[t._v("extra.nextOverflow")]),t._v(" 字段设置为 "),s("code",[t._v("nil")]),t._v("，表示预分配的溢出桶用完了，后面如果再需要溢出桶的时候，就只能直接 "),s("code",[t._v("new")]),t._v(" 一个了。")]),t._v(" "),s("li",[s("code",[t._v("buckets")]),t._v(" 指针下面的普通桶和溢出桶所需要的内存大小都是 "),s("code",[t._v("t.bucketsize")]),t._v("，也就是 "),s("code",[t._v("bmap")]),t._v(" 所需要的内存大小（当然是内存对齐之后的）。")])]),t._v(" "),s("p",[t._v("具体实现如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// makeBucketArray 初始化 map bucket 底层的数组（分配 buckets 的内存）。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1<<b 是要分配的最小存储桶数。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dirtyalloc 应该是 nil（不为 nil，表示清空 map），或者是 makeBucketArray 之前使用相同的 t 和 b 参数分配的桶数组。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 dirtyalloc 为 nil，将分配一段新的内存；否则将清除 dirtyalloc 指向的内存，将其作为新分配的内存。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// t：底层表示 map 的类型")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b：bucket 的大小为 2^b")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dirtyalloc: 不为 nil 表示要清空，用于 mapclear 函数。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回值：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// buckets：正常桶数组入口")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// nextOverflow：溢出桶数组入口")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("makeBucketArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dirtyalloc unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 数量 = 1 << b")]),t._v("\n   base "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketShift")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   nbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" base\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 对于小的 b，溢出桶不太可能。避免计算开销。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 桶的数量小于 2^4 时候，由于数据较少、使用溢出桶的可能性较低，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 会省略创建溢出桶的过程以减少额外开销。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但是大于等于 2^4 的时候，使用到溢出桶的可能性就会比较大，所以需要预先分配溢出桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 大于等于 2^4 的时候，额外创建 2^(B-4) 个溢出桶。")]),t._v("\n      nbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketShift")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      sz "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" nbuckets "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶所需要的内存大小")]),t._v("\n      up "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("roundupsize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算需要的内存大小")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" up "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" sz "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 分配的内存与实际需要的内存不一样，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 可能会比 sz 大一点，重新计算 nbuckets。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 下面的 nbuckets 才是最终的 bucket 数量（普通桶 + 溢出桶的数量）")]),t._v("\n         nbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" up "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// buckets 所在的内存初始化/清空（mapclear）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" dirtyalloc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建新的 bucket 数组")]),t._v("\n      buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newarray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清空原有的内存")]),t._v("\n      buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dirtyalloc\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// buckets 所需要的总内存大小（单位：字节）")]),t._v("\n      size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" nbuckets\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清空 buckets 开始的 size 字节大小的内存")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ptrdata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 有指针")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrHasPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrNoHeapPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 上面 b >= 4 的情况")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" base "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" nbuckets "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理一下预先分配的溢出桶。")]),t._v("\n      nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" base"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// buckets 和溢出桶内存是相邻的，计算第一个溢出桶的指针")]),t._v("\n      last "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nbuckets"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 最后一个溢出桶")]),t._v("\n      last"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setoverflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                             "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 最后一个溢出桶的 overflow 指针链接到第一个普通桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   \n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回普通桶、溢出桶的指针")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nextOverflow\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br")])]),s("h2",{attrs:{id:"map-定位-key-的实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-定位-key-的实现"}},[t._v("#")]),t._v(" map 定位 key 的实现")]),t._v(" "),s("p",[t._v("我们从上面的讲解中应该很清楚 "),s("code",[t._v("map")]),t._v(" 中 "),s("code",[t._v("bucket")]),t._v(" 这个数据结构了（上面的 "),s("code",[t._v("bmap")]),t._v(" 那个图），在做查找、修改、删除操作的时候， 都需要先根据 "),s("code",[t._v("key")]),t._v(" 找到具体的键值对保存在哪一个 "),s("code",[t._v("bucket")]),t._v(" 以及 "),s("code",[t._v("bucket")]),t._v(" 中的哪一个位置，所以这个操作其实是非常关键的。 在开始下文之前，就先来讲讲 "),s("code",[t._v("map")]),t._v(" 中是如何定位一个 "),s("code",[t._v("key")]),t._v(" 的。")]),t._v(" "),s("p",[t._v("其实定位的过程比较简单，假设现在要查找一个 "),s("code",[t._v("key")]),t._v("，那定位 "),s("code",[t._v("key")]),t._v(" 的大概步骤如下：")]),t._v(" "),s("ol",[s("li",[t._v("计算 "),s("code",[t._v("hash")]),t._v(": 根据 "),s("code",[t._v("key")]),t._v(" 计算出其哈希值 "),s("code",[t._v("hash")]),t._v("。")]),t._v(" "),s("li",[t._v("计算 "),s("code",[t._v("bucket")]),t._v(": 哈希值对 "),s("code",[t._v("buckets")]),t._v(" 长度取模（"),s("code",[t._v("hash % len(buckets)")]),t._v("），不过实际实现的时候使用了一种优化的方式，位运算（"),s("code",[t._v("hash & (2^B - 1)")]),t._v("），也就是由哈希值的最低 "),s("code",[t._v("B")]),t._v(" 位来决定 "),s("code",[t._v("key")]),t._v(" 最终使用哪一个 "),s("code",[t._v("bucket")]),t._v("（结果跟直接取模不一样，但是思想一样，都能保证得出的结果落在 "),s("code",[t._v("len(buckets)")]),t._v(" 范围内）。")]),t._v(" "),s("li",[t._v("遍历 "),s("code",[t._v("bucket")]),t._v("（先是普通桶）里面的每一个槽（有 8 个），比较哈希值的最高 8 位（8 bit，也就是 "),s("code",[t._v("tophash")]),t._v("）是否相等，如果相等，则获取存储在 "),s("code",[t._v("bucket")]),t._v(" 里面的 "),s("code",[t._v("key")]),t._v("，跟我们需要定位的 "),s("code",[t._v("key")]),t._v(" 做比较，如果相等，则说明已经找到了 "),s("code",[t._v("key")]),t._v("，如果 "),s("code",[t._v("key")]),t._v(" 不相等，则继续遍历下一个槽，直到 "),s("code",[t._v("bucket")]),t._v(" 中所有的槽都被遍历完毕。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("bucket")]),t._v(" 里面的 8 个槽都遍历完了，仍然没有找到我们需要找的 "),s("code",[t._v("key")]),t._v("。那么会从 "),s("code",[t._v("bucket")]),t._v(" 的溢出桶去查找，溢出桶内的查找过程跟普通桶内的查找过程是一样的。")]),t._v(" "),s("li",[t._v("如此遍历，直到所有溢出桶都遍历完（在找不到的情况下才会遍历 "),s("code",[t._v("bucket")]),t._v(" （普通桶）所有的溢出桶）。")])]),t._v(" "),s("p",[t._v("这个查找过程可以表示为下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/14.webp",alt:"map_4_1.png"}})]),t._v(" "),s("p",[t._v("注意："),s("strong",[t._v("确定一个 "),s("code",[t._v("key")]),t._v(" 需要 "),s("code",[t._v("tophash")]),t._v(" 和 "),s("code",[t._v("key")]),t._v(" 都相等，如果 "),s("code",[t._v("tophash")]),t._v(" 相等而 "),s("code",[t._v("key")]),t._v(" 不相等，则需要继续比较 "),s("code",[t._v("bucket")]),t._v(" 中其他的槽。")])]),t._v(" "),s("h2",{attrs:{id:"map-读取数据的实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-读取数据的实现"}},[t._v("#")]),t._v(" map 读取数据的实现")]),t._v(" "),s("p",[t._v("从 "),s("code",[t._v("map")]),t._v(" 中读取某一个键的方法主要有三个："),s("code",[t._v("mapaccess1")]),t._v("、"),s("code",[t._v("mapaccess2")]),t._v("、"),s("code",[t._v("mapaccessK")]),t._v("，这三个方法的代码其实是大同小异的，所以这里只拿 "),s("code",[t._v("mapaccessK")]),t._v(" 来讲解。")]),t._v(" "),s("p",[t._v("这三个方法的不同之处在于：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("mapaccess1")]),t._v(" 只返回 "),s("code",[t._v("key")]),t._v(" 对应的值，对应 "),s("code",[t._v('v := map["k"]')]),t._v(" 这种写法。")]),t._v(" "),s("li",[s("code",[t._v("mapaccess2")]),t._v(" 返回 "),s("code",[t._v("key")]),t._v(" 对应的值，以及是否存在的标志，对应 "),s("code",[t._v('v, ok := map["k"]')]),t._v(" 这种写法。")]),t._v(" "),s("li",[s("code",[t._v("mapaccessK")]),t._v(" 用于遍历 "),s("code",[t._v("map")]),t._v(" 的时候，返回 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v("，对应 "),s("code",[t._v("for k, v := range map {}")]),t._v(" 这种写法（在迭代的时候在 "),s("code",[t._v("mapiternext")]),t._v(" 里面调用）。")])]),t._v(" "),s("h3",{attrs:{id:"mapaccessk-的查找步骤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapaccessk-的查找步骤"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapaccessK")]),t._v(" 的查找步骤")]),t._v(" "),s("p",[s("code",[t._v("mapaccessK")]),t._v(" 的查找步骤大概就是上一个图说的，只不过下面的描述更加详细一点（em... 有点重复了）：")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("判断 "),s("code",[t._v("map")]),t._v(" 是否为空，为空直接返回")])]),t._v(" "),s("li",[s("p",[t._v("计算 "),s("code",[t._v("key")]),t._v(" 对应的哈希值 => "),s("code",[t._v("hash")])])]),t._v(" "),s("li",[s("p",[t._v("计算桶的掩码 => "),s("code",[t._v("m")]),t._v("，"),s("code",[t._v("hash & m")]),t._v(" 得到 "),s("code",[t._v("bucket")]),t._v(" 的索引")])]),t._v(" "),s("li",[s("p",[t._v("判断是否正在扩容，如果是，需要判断 key 对应的桶的数据是否已经被迁移到新的桶里面：")]),t._v(" "),s("ul",[s("li",[t._v("如果是，则需要从新的桶里面查找。")]),t._v(" "),s("li",[t._v("如果还没有被迁移，则需要从旧桶中读取。")])])]),t._v(" "),s("li",[s("p",[t._v("计算 "),s("code",[t._v("tophash")]),t._v(" => "),s("code",[t._v("top")]),t._v("（也就是 "),s("code",[t._v("hash")]),t._v(" 的最高 8 位）")])]),t._v(" "),s("li",[s("p",[t._v("遍历找到的桶的每一个槽（")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("slot/cell\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("）")]),t._v(" "),s("ul",[s("li",[t._v("比较 "),s("code",[t._v("tophash")]),t._v(" 是否相等")]),t._v(" "),s("li",[t._v("如果不等，判断桶后面是否都没有数据了（"),s("code",[t._v("b.tophash[i] == emptyRest")]),t._v("）")]),t._v(" "),s("li",[t._v("如果没有数据了，跳出循环 => 找不到 "),s("code",[t._v("key")]),t._v(" 对应的值")]),t._v(" "),s("li",[t._v("如果还有数据，则继续遍历下一个槽")])])]),t._v(" "),s("li",[s("p",[t._v("如果找到一个槽的")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("tophash\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("跟上面计算的")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("tophash\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("相等，则比较")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("key\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("是否相等")]),t._v(" "),s("ul",[s("li",[t._v("是，则返回对应的值（"),s("strong",[s("code",[t._v("tophash")]),t._v(" 和 "),s("code",[t._v("key")]),t._v(" 都相等，则表明找到了相应的 "),s("code",[t._v("key")]),t._v("，返回对应的值")]),t._v("）。")]),t._v(" "),s("li",[t._v("否，继续遍历下一个槽（依然是先比较 "),s("code",[t._v("tophash")]),t._v("，"),s("code",[t._v("tophash")]),t._v(" 相等则再比较 "),s("code",[t._v("key")]),t._v(" 是否相等）")])])]),t._v(" "),s("li",[s("p",[t._v("溢出桶也找不到，则返回零值（及是否找到的标志）。")])])]),t._v(" "),s("h3",{attrs:{id:"mapaccessk-的实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapaccessk-的实现"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapaccessK")]),t._v(" 的实现")]),t._v(" "),s("p",[t._v("对于整型的键值的 "),s("code",[t._v("map")]),t._v("，go 里面有针对优化的实现，但其实代码逻辑上都是差不多的，所以不细说了。下面来看看 "),s("code",[t._v("mapaccessK")]),t._v(" 的实现：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在迭代 map 的时候，返回键值对。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// t: map 类型元信息（记录了 map 中的 key/value 的类型等信息，比如 key 的大小，可用于计算内存偏移）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// h: map 结构体类型（也就是实际的哈希表类型）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key: 需要查找的 key")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回值：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 第一个返回值：当前遍历到的 key 的指针")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 第二个返回值：当前遍历到的 key 对应的值的指针")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapaccessK")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 是空的")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 根据 key 和 hash0 计算 hash")]),t._v("\n   hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// hash 的掩码，类似 IP 的掩码")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（比如，假设 B = 3，一共有 8 个元素，索引为 0～7，那么掩码 m 表示为二进制就是 111）。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用于跟 hash 值做 & 运算（hash & m），得到 hash 对应 bucket 的索引（0～m）")]),t._v("\n   m "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 根据 hash 计算 bucket 地址，b 是 hash 匹配到的 bucket")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正在扩容，如果 bucket 还没迁移到新的地址，则需要从 oldbuckets 中访问")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" c "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" c "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 不是等量扩容，需要从旧桶中读取，所以 m 要移除最高位（右移一位）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sameSizeGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 不是等量扩容，则将 m 除以 2，因为是 2 倍扩容，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 所以 buckets 的大小为 oldbuckets 长度的 2 倍，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 除以 2 才是旧的桶数量")]),t._v("\n         m "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 在 oldbuckets 中的地址")]),t._v("\n      oldb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuated")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 尚未迁移到新的 buckets 中，还在 oldbuckets 中")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 则需要从旧桶中查找")]),t._v("\n         b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oldb\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 tophash")]),t._v("\n   top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tophash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbucketloop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从 bucket 中查找，一个 bucket 可以存储的元素个数是 bucketCnt，也就是 8")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 不匹配，肯定不是这个槽")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 剩余的槽是空的，不用再找了，跳出循环")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" emptyRest "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v(" bucketloop\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续比较下一个槽")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 匹配")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 接下来将这个槽的 key 取出来")]),t._v("\n         k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 是指针类型")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 比较 key 跟 k 是否相等")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 相等则读取对应的值（表示找到了匹配的 key 了）")]),t._v("\n            e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 值是指针类型")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 找到了，返回键值对")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         \n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意：执行到这里，说明 tophash 相等，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但是 key 不匹配，仍然需要继续遍历。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 普通桶和溢出桶的所有槽都找不到，返回 nil")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br")])]),s("p",[t._v("这里需要注意的是，如果在扩容的过程中查找，会先判断数据是否已经被迁移到新桶，如果还没有被迁移，则需要从旧的桶中查找。")]),t._v(" "),s("h3",{attrs:{id:"mapaccessk-关键代码"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapaccessk-关键代码"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapaccessK")]),t._v(" 关键代码")]),t._v(" "),s("ol",[s("li",[s("code",[t._v("bucket")]),t._v(" 的定位代码")])]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[t._v("m "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 就是定位到的 bucket 所在的内存地址")]),t._v("\nb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("m"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[s("code",[t._v("bucket")]),t._v(" 索引（"),s("code",[t._v("hash & m")]),t._v("）的定位方式如下：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/15.webp",alt:"map_4_2.png"}})]),t._v(" "),s("p",[t._v("因为 "),s("code",[t._v("buckets")]),t._v(" 是指向 "),s("code",[t._v("bmap")]),t._v(" 的指针数组，所以我们可以通过 "),s("code",[t._v("buckets")]),t._v(" 加上 "),s("code",[t._v("bucket")]),t._v(" 的索引，就可以定位到 "),s("code",[t._v("bucket")]),t._v(" 的内存地址。 因为每一个 "),s("code",[t._v("bmap")]),t._v(" 的大小是 "),s("code",[t._v("t.bucketsize")]),t._v("，所以 "),s("code",[t._v("bucket")]),t._v(" 的索引乘以 "),s("code",[t._v("t.bucketsize")]),t._v("，也即 "),s("code",[t._v("(hash&m)*uintptr(t.bucketsize)")]),t._v("，就是 "),s("code",[t._v("bucket")]),t._v(" 的相对偏移量。 然后 "),s("code",[t._v("buckets")]),t._v(" 的地址加上 "),s("code",[t._v("bucket")]),t._v(" 的相对偏移量，就可以定位到 "),s("code",[t._v("bucket")]),t._v(" 的内存地址。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/16.webp",alt:"map_4_3.png"}})]),t._v(" "),s("p",[t._v("我们需要注意的是，我们计算得到 "),s("code",[t._v("bucket")]),t._v(" 的指针后，需要将其转换为 "),s("code",[t._v("bmap")]),t._v(" 类型的指针，才能进行后续的操作。")]),t._v(" "),s("p",[t._v("然后 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 也是通过类似的指针运算来定位的。需要说明的是：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("add")]),t._v(" 函数是做指针算术运算的函数，具体来说就是 "),s("code",[t._v("add(a, b)")]),t._v(" 就是 "),s("code",[t._v("a")]),t._v(" 地址加上 "),s("code",[t._v("b")]),t._v(" 的偏移量，返回的是 "),s("code",[t._v("unsafe.Pointer")]),t._v(" 类型的指针。")]),t._v(" "),s("li",[s("code",[t._v("unsafe.Pointer(b)")]),t._v(" 是 "),s("code",[t._v("bucket")]),t._v(" 的内存地址")]),t._v(" "),s("li",[s("code",[t._v("dataOffset")]),t._v(" 是 "),s("code",[t._v("bucket")]),t._v(" 中第一个 "),s("code",[t._v("key")]),t._v(" 的地址偏移量，")]),t._v(" "),s("li",[s("code",[t._v("t.keysize")]),t._v(" 是 "),s("code",[t._v("key")]),t._v(" 的大小")]),t._v(" "),s("li",[s("code",[t._v("t.elemsize")]),t._v(" 是 "),s("code",[t._v("map")]),t._v(" 值的大小")]),t._v(" "),s("li",[s("code",[t._v("bucketCnt")]),t._v(" 是 "),s("code",[t._v("bucket")]),t._v(" 中槽的数量（8 个，预定义的常量）。")])]),t._v(" "),s("p",[t._v("然后大家可以结合上面的 "),s("code",[t._v("bmap")]),t._v(" 内存布局图来理解上面指针计算的代码。")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 读取 bucket 中的第 i 个 key。")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 读取 bucket 中的第 i 个 value")]),t._v("\ne "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("ol",[s("li",[s("code",[t._v("b.tophash[i] == emptyRest")]),t._v(" 判断的理解")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/17.webp",alt:"map_4_4.png"}})]),t._v(" "),s("p",[s("code",[t._v("emptyRest")]),t._v(" 是一个比较特殊的标记，它表示 "),s("code",[t._v("bucket")]),t._v(" 中的后续槽都是空的。 在 "),s("code",[t._v("map")]),t._v(" 删除元素的时候，会判断后面还有没有元素，如果没有元素的话，就会将 "),s("code",[t._v("b.tophash[i]")]),t._v(" 设置为 "),s("code",[t._v("emptyRest")]),t._v("。 这样在查找的时候，就可以通过 "),s("code",[t._v("b.tophash[i] == emptyRest")]),t._v(" 来判断后面的槽都是空的，就不需要继续遍历了。")]),t._v(" "),s("ol",[s("li",[s("code",[t._v("indirectkey")]),t._v(" 和 "),s("code",[t._v("indirectelem")]),t._v(" 的理解")])]),t._v(" "),s("p",[t._v("我们发现上面读取 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 的时候有一个比较特别的操作：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])]),s("p",[t._v("相信不少读者第一次看到这几行代码的时候会跟我一样有点懵逼，从 "),s("code",[t._v("maptype")]),t._v(" 的定义我们可以看出一点端倪：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// store ptr to key instead of key itself")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" mt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 存储了 key 的指针，而不是 key 本身")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// store ptr to elem instead of elem itself")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" mt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 存储了 elem 的指针，而不是 elem 本身")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])]),s("p",[t._v("简单来说，就是 go 底层在有时候会将 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 保存为指针，而不是直接保存 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 本身。 这样一来，go 里面的 "),s("code",[t._v("map")]),t._v(" 操作就需要根据 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 的类型来判断是否需要进行指针解引用，也就是取出实际的 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v("。")]),t._v(" "),s("h2",{attrs:{id:"map-写入和修改的设计与实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-写入和修改的设计与实现"}},[t._v("#")]),t._v(" map 写入和修改的设计与实现")]),t._v(" "),s("p",[t._v("在 go 中，"),s("code",[t._v("map")]),t._v(" 的写入和修改都是通过 "),s("code",[t._v("mapassign")]),t._v(" 函数来实现的，因为写入和修改本质上是同一个操作，都是找到对应的 "),s("code",[t._v("key")]),t._v("，然后修改对应的值。")]),t._v(" "),s("h3",{attrs:{id:"mapassign-的实现步骤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapassign-的实现步骤"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapassign")]),t._v(" 的实现步骤")]),t._v(" "),s("ol",[s("li",[t._v("计算 "),s("code",[t._v("key")]),t._v(" 的 "),s("code",[t._v("hash")]),t._v(" 值。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("buckets")]),t._v(" 还没有初始化，则进行分配内存。")]),t._v(" "),s("li",[t._v("计算出 "),s("code",[t._v("bucket")]),t._v(" 的索引。")]),t._v(" "),s("li",[t._v("如果正在扩容，则迁移当前即将要操作的 "),s("code",[t._v("bucket")]),t._v("（也就是上一步计算出来的索引对应的 "),s("code",[t._v("bucket")]),t._v("）。")]),t._v(" "),s("li",[t._v("计算 "),s("code",[t._v("tophash")]),t._v("。")]),t._v(" "),s("li",[t._v("遍历 "),s("code",[t._v("bucket")]),t._v(" 中的槽，记录下第一个空的槽的 "),s("code",[t._v("tophash")]),t._v(" 索引指针、"),s("code",[t._v("key")]),t._v(" 指针，"),s("code",[t._v("value")]),t._v(" 指针。如果最后找不到 "),s("code",[t._v("key")]),t._v(" 的时候，会插入到这里。")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("bucket")]),t._v(" 的所有桶都找不到 "),s("code",[t._v("key")]),t._v("，则判断是否需要扩容，需要的话就进行扩容，然后再执行 6 的操作。")]),t._v(" "),s("li",[t._v("另外一种情况，不需要扩容，而且 "),s("code",[t._v("bucket")]),t._v(" 以及它的溢出桶也满了，则需要新建溢出桶来保存 "),s("code",[t._v("key")])]),t._v(" "),s("li",[t._v("最后，将 "),s("code",[t._v("tophash/key/value")]),t._v(" 插入到需要 "),s("code",[t._v("bucket")]),t._v(" 第一个空的槽。又或者如果已经存在，对 "),s("code",[t._v("value")]),t._v(" 进行更新。")])]),t._v(" "),s("h3",{attrs:{id:"mapassign-图解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapassign-图解"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapassign")]),t._v(" 图解")]),t._v(" "),s("p",[t._v("可以分两种情况：")]),t._v(" "),s("ol",[s("li",[t._v("普通桶和溢出桶都找不到 "),s("code",[t._v("key")]),t._v(" 的情况下，将 "),s("code",[t._v("key")]),t._v(" 插入桶中第一个空的槽")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/18.webp",alt:"map_5_1.png"}})]),t._v(" "),s("ol",[s("li",[t._v("在 "),s("code",[t._v("bucket")]),t._v(" 中找到了 "),s("code",[t._v("key")]),t._v("，则会对其进行更新")])]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/19.webp",alt:"map_5_2.png"}})]),t._v(" "),s("p",[t._v("对于 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 的存储，有以下两种情况：")]),t._v(" "),s("ol",[s("li",[t._v("直接保存在 "),s("code",[t._v("bucket")]),t._v(" 中：")])]),t._v(" "),s("p",[t._v("这样在我们需要修改 "),s("code",[t._v("key")]),t._v("/"),s("code",[t._v("value")]),t._v(" 的时候，通过 "),s("code",[t._v("bucket")]),t._v(" 加上 "),s("code",[t._v("索引 * keysize/valuesize")]),t._v(" 就可以得到对应键值存储的实际内存。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/20.webp",alt:"map_5_4.png"}})]),t._v(" "),s("ol",[s("li",[t._v("在 "),s("code",[t._v("bucket")]),t._v(" 中保存的是 "),s("code",[t._v("key/value")]),t._v(" 的内存地址（"),s("code",[t._v("unsafe.Pointer")]),t._v("）类型")])]),t._v(" "),s("p",[t._v("这样如果我们需要修改/读取实际的键值的时候，就需要先从 "),s("code",[t._v("bucket")]),t._v(" 中获取这个指针，然后解引用得到实际存储键值的内存指针。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/21.webp",alt:"map_5_3.png"}})]),t._v(" "),s("p",[t._v("注意：在我们做如下运算的时候（假设 "),s("code",[t._v("bucket")]),t._v(" 没有存储实际的 "),s("code",[t._v("key")]),t._v("，而是存储了 "),s("code",[t._v("key")]),t._v(" 的指针）：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("得到的结果是，指向 "),s("code",[t._v("keys[i]")]),t._v("（也就是第 "),s("code",[t._v("i")]),t._v(" 个 "),s("code",[t._v("key")]),t._v("）的指针（"),s("code",[t._v("unsafe.Pointer")]),t._v(" 类型）。 如果 "),s("code",[t._v("key")]),t._v(" 保存在 "),s("code",[t._v("bucket")]),t._v(" 中，通过这个指针我们就可以读写 "),s("code",[t._v("key")]),t._v(" 了。 否则，表示这个指针指向的内存存储的只是一个指针，如果我们需要修改实际的 "),s("code",[t._v("key")]),t._v("， 就需要通过 "),s("code",[t._v("key")]),t._v(" 指针（"),s("code",[t._v("A")]),t._v("）拿到这里存储的指针（"),s("code",[t._v("B")]),t._v("），然后再通过 "),s("code",[t._v("B")]),t._v(" 来修改实际的 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/22.webp",alt:"map_5_5.png"}})]),t._v(" "),s("blockquote",[s("p",[t._v("对 "),s("code",[t._v("value")]),t._v(" 的读写同理。")])]),t._v(" "),s("h3",{attrs:{id:"mapassign-源码剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapassign-源码剖析"}},[t._v("#")]),t._v(" "),s("code",[t._v("mapassign")]),t._v(" 源码剖析")]),t._v(" "),s("blockquote",[s("p",[t._v("扩容的操作后面会有解析，这一节就先不细说了。")])]),t._v(" "),s("p",[t._v("这个函数的定义如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 功能：插入 key 或者修改 map 中的 key")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// t：map 类型元信息")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// h：map 结构体（实际保存键值对的地方）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key：我们要修改或者插入的 key")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回值：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 只有一个，那就是我们插入或者修改之后的值。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapassign")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("panic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("plainError")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"assignment to entry in nil map"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 并发写，直接报错")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("hashWriting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fatal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"concurrent map writes"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 key 的哈希值（是一个无符号整数）")]),t._v("\n   hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在调用 t.hasher 之后设置 hashWriting，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 因为 t.hasher 可能会 panic，在这种情况下，我们实际上还没有进行写操作。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 写标记。（如果读操作发现有写标志则会报错）")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^=")]),t._v(" hashWriting\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 buckets 是空，则新建一个 bucket")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newobject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// newarray(t.bucket, 1)")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nagain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 指示第几个 bucket（命名貌似有点不合适）")]),t._v("\n   bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正在扩容的话，则将 bucket 迁移到新桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growWork")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 为即将要写入的 bucket")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 key 的 tophash")]),t._v("\n   top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tophash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 要插入的 tophash 地址")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" insertk unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 要插入的键地址")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" elem unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 要插入的值地址")]),t._v("\nbucketloop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 循环 bucket 的槽")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 不匹配，并且当前槽为空，则记录要插入的位置（找不到 key 的时候，最后会插入到这里）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isEmpty")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n               insertk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 为什么找到了可以插入的地方，不中断循环？")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 原因是，这个函数是寻找已经存在的 key 的（插入和修改都是用这个函数），")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果对应的 key 保存到了后面的槽里面的话，这里直接中断循环就是不对的。")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 因为在这种情况下，理应更新后面的那个槽。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 没有找到对应的 key，同时 bucket 中剩余的槽都是空的。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// （这意味着 map 中找不到 key，需要插入这个 key 了）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 中止对 bucket 里面槽的遍历。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" emptyRest "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v(" bucketloop\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 虽然找到了空闲的槽，但还是要查看 bucket 中的其他槽，看 key 是否已经存在。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// （如果存在的话，修改 key 对应的值就可以了，当然这个函数里面不会修改，而是返回值的地址，从函数外部修改）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个很好理解，保存值的指针都拿到了，想修改就很简单了。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 key 已经存在，则返回已存在 key 的对应的 elem 的地址。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 相等，依然需要比较 key 是否相等。")]),t._v("\n         k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但是 key 不想等，继续比较下一个槽")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 相等、key 也相等，说明已经存在，更新它即可")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用 key 更新 k")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("needkeyupdate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("typedmemmove")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 value 所在的地址")]),t._v("\n         elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 找到了 key，直接跳转到 done")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),t._v(" done\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前的桶里面所有槽都找不到。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续遍历溢出桶（在溢出桶中查找 key 是否存在/有没有空余的槽）")]),t._v("\n      ovf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ovf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶也找不到，跳出循环")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 指向下一个溢出桶，下次循环遍历这个溢出桶")]),t._v("\n      b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ovf\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 未找到 key，需要插入这个新的 key。")]),t._v("\n   \n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果我们达到了最大负载系数或者我们有太多的溢出桶，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 同时，如果还没有开始扩容，那么现在开始扩容。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tooManyOverflowBuckets")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("noverflow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容哈希表会使所有内容无效，因此需要再次尝试插入。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// （上面循环获取到的插入位置的指针已经失效了，扩容之后插入的位置改变了，所以需要再次计算要插入的 bucket，以及要插入的槽中的位置）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),t._v(" again\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 表明没有找到可以插入的地方，则新建一个溢出桶来保存，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶的第一个元素就用来保存 key，返回溢出桶第一个元素 elem 的地址")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// （这意味着，我们要插入的桶，所有的槽都有数据了，并且也不是我们要找的 key，所需要溢出桶了）")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前存储桶及其连接的所有溢出存储桶已满，分配一个新的溢出桶。")]),t._v("\n      newb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newoverflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶的第一个 tophash 的指针")]),t._v("\n      inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("newb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶的第一个 key 的指针")]),t._v("\n      insertk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 溢出桶的第一个 value 的指针")]),t._v("\n      elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insertk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在插入位置存储新 key/elem")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("                   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这意味着需要给 key 分配内存来保存它")]),t._v("\n      kmem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newobject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 给 key 分配内存（kmem 是保存 key 的内存指针）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insertk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" kmem "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 里面的 key 保存新分配的内存指针")]),t._v("\n      insertk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" kmem                     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// insertk 指向新分配的地址（跟上一行并不重复）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 最终效果是，insertk 和 kmem 指向了新分配的保存 key 的内存地址。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当然，insertk = kmem 不需要也可以，但这样一来下面也要改成：")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// if t.indirectkey() {")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     typedmemmove(t.key, kmem, key)")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// } else {")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     typedmemmove(t.key, insertk, key)")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// }")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      vmem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newobject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("       "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 给 elem 分配内存")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vmem "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 里面 elem 的槽保存新分配的地址")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 移动 key 到 insertK（保存新的 key）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("typedmemmove")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insertk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 保存 tophash")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("inserti "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" top\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 元素个数 +1")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n\ndone"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 并发写则报错（多个协程同时写 map）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("hashWriting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 写标志被清除了")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fatal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"concurrent map writes"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除写标志")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&^=")]),t._v(" hashWriting\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 中的值保存的是指针，这个时候就不能返回 bucket 中值的地址了，而是返回 bucket 中值指向的另外一个地址的指针。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取指向 elem 实际存储地址的指针")]),t._v("\n      elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回存储值的指针")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" elem\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br"),s("span",{staticClass:"line-number"},[t._v("123")]),s("br"),s("span",{staticClass:"line-number"},[t._v("124")]),s("br"),s("span",{staticClass:"line-number"},[t._v("125")]),s("br"),s("span",{staticClass:"line-number"},[t._v("126")]),s("br"),s("span",{staticClass:"line-number"},[t._v("127")]),s("br"),s("span",{staticClass:"line-number"},[t._v("128")]),s("br"),s("span",{staticClass:"line-number"},[t._v("129")]),s("br"),s("span",{staticClass:"line-number"},[t._v("130")]),s("br"),s("span",{staticClass:"line-number"},[t._v("131")]),s("br"),s("span",{staticClass:"line-number"},[t._v("132")]),s("br"),s("span",{staticClass:"line-number"},[t._v("133")]),s("br"),s("span",{staticClass:"line-number"},[t._v("134")]),s("br"),s("span",{staticClass:"line-number"},[t._v("135")]),s("br"),s("span",{staticClass:"line-number"},[t._v("136")]),s("br"),s("span",{staticClass:"line-number"},[t._v("137")]),s("br"),s("span",{staticClass:"line-number"},[t._v("138")]),s("br"),s("span",{staticClass:"line-number"},[t._v("139")]),s("br"),s("span",{staticClass:"line-number"},[t._v("140")]),s("br"),s("span",{staticClass:"line-number"},[t._v("141")]),s("br"),s("span",{staticClass:"line-number"},[t._v("142")]),s("br"),s("span",{staticClass:"line-number"},[t._v("143")]),s("br"),s("span",{staticClass:"line-number"},[t._v("144")]),s("br"),s("span",{staticClass:"line-number"},[t._v("145")]),s("br"),s("span",{staticClass:"line-number"},[t._v("146")]),s("br"),s("span",{staticClass:"line-number"},[t._v("147")]),s("br"),s("span",{staticClass:"line-number"},[t._v("148")]),s("br"),s("span",{staticClass:"line-number"},[t._v("149")]),s("br"),s("span",{staticClass:"line-number"},[t._v("150")]),s("br"),s("span",{staticClass:"line-number"},[t._v("151")]),s("br"),s("span",{staticClass:"line-number"},[t._v("152")]),s("br"),s("span",{staticClass:"line-number"},[t._v("153")]),s("br"),s("span",{staticClass:"line-number"},[t._v("154")]),s("br"),s("span",{staticClass:"line-number"},[t._v("155")]),s("br"),s("span",{staticClass:"line-number"},[t._v("156")]),s("br"),s("span",{staticClass:"line-number"},[t._v("157")]),s("br"),s("span",{staticClass:"line-number"},[t._v("158")]),s("br"),s("span",{staticClass:"line-number"},[t._v("159")]),s("br"),s("span",{staticClass:"line-number"},[t._v("160")]),s("br"),s("span",{staticClass:"line-number"},[t._v("161")]),s("br"),s("span",{staticClass:"line-number"},[t._v("162")]),s("br"),s("span",{staticClass:"line-number"},[t._v("163")]),s("br"),s("span",{staticClass:"line-number"},[t._v("164")]),s("br"),s("span",{staticClass:"line-number"},[t._v("165")]),s("br")])]),s("p",[t._v("有几点要注意的：")]),t._v(" "),s("ol",[s("li",[t._v("go 中 "),s("code",[t._v("map")]),t._v(" 是不允许并发读写的，如果有，直接报错。")]),t._v(" "),s("li",[t._v("这里面我们看到了有扩容的操作，"),s("strong",[t._v("在 go 中，"),s("code",[t._v("map")]),t._v(" 的扩容发生在插入、修改和删除的时候，是一种渐进式扩容的方式，每次扩容会迁移两个 "),s("code",[t._v("bucket")])]),t._v("，详细的后面讲到扩容的时候会细说。")]),t._v(" "),s("li",[t._v("在 "),s("code",[t._v("bucketloop")]),t._v(" 这个循环中，会记录下第一个空的槽，在找不到 "),s("code",[t._v("key")]),t._v(" 的时候会进行插入操作。")]),t._v(" "),s("li",[t._v("如果找到，则返回保存值的地址的指针。如果没找到，则将 "),s("code",[t._v("key")]),t._v(" 插入到上一步找到的空的槽中，如果也没有空的槽，则会新建溢出桶来保存新插入的 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("li",[t._v("在这个函数中，会判断插入之后是否超过负载因子，又或者溢出桶是否太多，来决定是否扩容。")])]),t._v(" "),s("blockquote",[s("p",[t._v("关于 "),s("code",[t._v("key")]),t._v(" 匹配的过程，其实跟上面的 "),s("code",[t._v("mapaccess")]),t._v(" 是一样的过程，先找普通桶，然后查找溢出桶。")])]),t._v(" "),s("h2",{attrs:{id:"map-删除-key-的实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-删除-key-的实现"}},[t._v("#")]),t._v(" map 删除 key 的实现")]),t._v(" "),s("p",[t._v("对于删除操作，其实有一些操作上面已经说过了，如如何定位一个 "),s("code",[t._v("key")]),t._v("。所以下面的讲述会侧重讲解跟删除操作密切相关的操作。")]),t._v(" "),s("h3",{attrs:{id:"map-删除-key-的步骤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-删除-key-的步骤"}},[t._v("#")]),t._v(" map 删除 key 的步骤")]),t._v(" "),s("ol",[s("li",[t._v("定位 "),s("code",[t._v("key")]),t._v(" 所在 "),s("code",[t._v("bucket")]),t._v("，计算 "),s("code",[t._v("tophash")]),t._v("。")]),t._v(" "),s("li",[t._v("遍历 "),s("code",[t._v("bucket")]),t._v(" 的每一个槽，比较 "),s("code",[t._v("tophash")]),t._v(" 以及 "),s("code",[t._v("key")]),t._v("，普通桶中查找不到会继续查找溢出桶。")]),t._v(" "),s("li",[t._v("如果查找到 "),s("code",[t._v("key")]),t._v(" 的话，会清空对应 "),s("code",[t._v("key")]),t._v(" 在 "),s("code",[t._v("bucket")]),t._v(" 内存中的 "),s("code",[t._v("tophash")]),t._v("、"),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v("。")]),t._v(" "),s("li",[t._v("如果后面的槽没有元素了，则设置 "),s("code",[t._v("emptyRest")]),t._v(" 标记。"),s("strong",[t._v("这样在后续查找的时候就可以避免不必要的搜索了。")])])]),t._v(" "),s("h3",{attrs:{id:"map-删除过程图解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-删除过程图解"}},[t._v("#")]),t._v(" map 删除过程图解")]),t._v(" "),s("p",[t._v("删除的过程比较简单，定位 "),s("code",[t._v("key")]),t._v(" 的过程上面有过详细的讲解了，这里只详细画图阐述一下 "),s("code",[t._v("emptyRest")]),t._v(" 的标记设置：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/23.webp",alt:"map_6_1.png"}})]),t._v(" "),s("h3",{attrs:{id:"map-删除源码剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-删除源码剖析"}},[t._v("#")]),t._v(" map 删除源码剖析")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从 map 中删除 key（以及对应的 elem）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// t：map 类型元数据的结构体")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// h：实际保存键值对的桶")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key：需要删除的 key")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapdelete")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 是空的")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 key 的类型不可哈希则 panic")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashMightPanic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// see issue 23734")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 并发写则抛出 fatal 错误")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("hashWriting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fatal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"concurrent map writes"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 key 的 hash")]),t._v("\n   hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在调用 t.hasher 之后设置 hashWriting，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 因为 t.hasher 可能会 panic ，在这种情况下，我们实际上没有执行 write（delete）。")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^=")]),t._v(" hashWriting\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 key 落在哪一个 bucket 中")]),t._v("\n   bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果正在扩容，则迁移 bucket 到新的内存地址中（迁移到新的桶）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// (迁移当前正在访问的 bucket)")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growWork")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取 bucket 实例（key 所在的 bucket）")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录原始的 bucket 实例")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（目的是为了方便加 emptyRest 标记）")]),t._v("\n   bOrig "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" b\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算 tophash")]),t._v("\n   top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tophash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsearch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在 bucket 内进行搜索")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历 bucket 的每一个槽")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 不想等的时候，需要判断后面是否还有元素")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从 i 开始 bucket 后面都是空的了，")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 中止搜索过程（去除写标记，函数执行完毕）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" emptyRest "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v(" search\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 还有元素，继续搜索")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 相等")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取 key 在 bucket 中的内存地址")]),t._v("\n         k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         k2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" k "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// k2 代表的是指向实际存储 key 的指针（unsafe.Pointer） ")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// k2 指向原始的地址")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            k2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 不想等，继续检查下一个 slot（continue）")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 只有在键中有指针时才清除键。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清空 key 的内存")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除 bucket 里面保存 key 的内存")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（bucket 只是存储了 key 的指针）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ptrdata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除包含指针的 key")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrHasPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 值的地址")]),t._v("\n         e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清空值")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除 bucket 里面保存 elem 的内存")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ptrdata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除包含指针的 elem（值）")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrHasPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除不包含指针的 elem 的内存")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrNoHeapPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 设置为空标记")]),t._v("\n         b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" emptyOne\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 bucket 现在以一堆 emptyOne 状态结束，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将这些状态更改为 emptyRest 状态。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 最好将其作为一个单独的函数，但 for 循环当前不可内联。（所以用 goto）")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 要删除的 key 是 bucket 里面的最后一个元素。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 同时还有溢出桶，并且溢出桶里面还有元素 => 表明当前删除的 key 不是 bucket 以及溢出桶里面的最后一个元素。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" emptyRest "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 不是最后一个元素")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),t._v(" notLast\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 要删除的 key 不是 bucket 的最后一个元素。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 并且后面还有元素。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" emptyRest "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),t._v(" notLast\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         \n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 执行到这里的时候，表明刚刚删除的 key 是 bucket 以及溢出桶中的最后一个元素。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果不是最后一个元素的话，上面的 if 判断已经跳转了。")]),t._v("\n         \n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 下面的 for 循环做的事情是：")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 将当前 key 的标志设置为：emptyRest，表示后面没有元素了。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 从 bucket 的第一个 key 出发遍历所有的槽（包含溢出桶），")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    将最后一个元素以后一直到被删除的 key 的中间的所有槽标记为 emptyRest")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 目的是，在后续遍历的时候可以避免一些不必要的查找操作，见到 emptyRest 就可以直接中断循环了。")]),t._v("\n\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 例子，bucket 里 key 的内存布局为 | nil | a | nil | nil | b | nil |")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 被删除的时候，b 以及 a 后面的两个元素都要标记为 emptyRest（溢出桶同理）")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 给当前遍历到的 bucket 槽打上 emptyRest 标记")]),t._v("\n            b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" emptyRest\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前的桶遍历完了（因为是从后往前遍历）")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 是普通桶（不是溢出桶）")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" bOrig "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 所有空的槽都处理完了")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 是上一次循环处理的桶")]),t._v("\n               c "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// c 是上一个 b ")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 查找上一个存储桶，在其最后一个条目处继续。 ")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如：bucket <- overflow1 <- overflow2 <- ... <- overflowN")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 假设 c 是 overflow2，那么下面的循环过后，b 就是 overflow1")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// prevB.overflow = b  => 找 prevB，也即：遍历完当前的桶，找前一个桶。")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bOrig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 指向了前一个 bucket（前一个桶）")]),t._v("\n\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理前一个 bucket 的最后一个槽")]),t._v("\n               i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续处理前一个槽")]),t._v("\n               i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 找到了一个不是空的槽，表示有数据了，不需要再打 emptyRest 标记了。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" emptyOne "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 被删除的元素如果不是最后一个元素，直接跳转到这里。")]),t._v("\n      notLast"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 找到了元素，并且删除了。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 的元素个数减 1")]),t._v("\n         h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 重置哈希种子，使攻击者更难重复触发哈希冲突。见 issue 25237。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastrand")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在 bucket 内找到了对应的元素，并且删除了。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 退出循环。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),t._v(" search\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果当前没有写标记，则抛出 fatal 错误（不能并发读写 map）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("hashWriting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fatal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"concurrent map writes"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 清除写标记")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&^=")]),t._v(" hashWriting\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br"),s("span",{staticClass:"line-number"},[t._v("123")]),s("br"),s("span",{staticClass:"line-number"},[t._v("124")]),s("br"),s("span",{staticClass:"line-number"},[t._v("125")]),s("br"),s("span",{staticClass:"line-number"},[t._v("126")]),s("br"),s("span",{staticClass:"line-number"},[t._v("127")]),s("br"),s("span",{staticClass:"line-number"},[t._v("128")]),s("br"),s("span",{staticClass:"line-number"},[t._v("129")]),s("br"),s("span",{staticClass:"line-number"},[t._v("130")]),s("br"),s("span",{staticClass:"line-number"},[t._v("131")]),s("br"),s("span",{staticClass:"line-number"},[t._v("132")]),s("br"),s("span",{staticClass:"line-number"},[t._v("133")]),s("br"),s("span",{staticClass:"line-number"},[t._v("134")]),s("br"),s("span",{staticClass:"line-number"},[t._v("135")]),s("br"),s("span",{staticClass:"line-number"},[t._v("136")]),s("br"),s("span",{staticClass:"line-number"},[t._v("137")]),s("br"),s("span",{staticClass:"line-number"},[t._v("138")]),s("br"),s("span",{staticClass:"line-number"},[t._v("139")]),s("br"),s("span",{staticClass:"line-number"},[t._v("140")]),s("br"),s("span",{staticClass:"line-number"},[t._v("141")]),s("br"),s("span",{staticClass:"line-number"},[t._v("142")]),s("br"),s("span",{staticClass:"line-number"},[t._v("143")]),s("br"),s("span",{staticClass:"line-number"},[t._v("144")]),s("br"),s("span",{staticClass:"line-number"},[t._v("145")]),s("br"),s("span",{staticClass:"line-number"},[t._v("146")]),s("br"),s("span",{staticClass:"line-number"},[t._v("147")]),s("br"),s("span",{staticClass:"line-number"},[t._v("148")]),s("br"),s("span",{staticClass:"line-number"},[t._v("149")]),s("br"),s("span",{staticClass:"line-number"},[t._v("150")]),s("br"),s("span",{staticClass:"line-number"},[t._v("151")]),s("br"),s("span",{staticClass:"line-number"},[t._v("152")]),s("br"),s("span",{staticClass:"line-number"},[t._v("153")]),s("br"),s("span",{staticClass:"line-number"},[t._v("154")]),s("br"),s("span",{staticClass:"line-number"},[t._v("155")]),s("br"),s("span",{staticClass:"line-number"},[t._v("156")]),s("br"),s("span",{staticClass:"line-number"},[t._v("157")]),s("br"),s("span",{staticClass:"line-number"},[t._v("158")]),s("br"),s("span",{staticClass:"line-number"},[t._v("159")]),s("br"),s("span",{staticClass:"line-number"},[t._v("160")]),s("br"),s("span",{staticClass:"line-number"},[t._v("161")]),s("br"),s("span",{staticClass:"line-number"},[t._v("162")]),s("br"),s("span",{staticClass:"line-number"},[t._v("163")]),s("br"),s("span",{staticClass:"line-number"},[t._v("164")]),s("br"),s("span",{staticClass:"line-number"},[t._v("165")]),s("br"),s("span",{staticClass:"line-number"},[t._v("166")]),s("br"),s("span",{staticClass:"line-number"},[t._v("167")]),s("br"),s("span",{staticClass:"line-number"},[t._v("168")]),s("br"),s("span",{staticClass:"line-number"},[t._v("169")]),s("br"),s("span",{staticClass:"line-number"},[t._v("170")]),s("br"),s("span",{staticClass:"line-number"},[t._v("171")]),s("br"),s("span",{staticClass:"line-number"},[t._v("172")]),s("br"),s("span",{staticClass:"line-number"},[t._v("173")]),s("br")])]),s("p",[t._v("注意：")]),t._v(" "),s("ol",[s("li",[t._v("go "),s("code",[t._v("map")]),t._v(" 不允许并发写，所以如果发现有并发读写，则抛出 fatal 错误。")]),t._v(" "),s("li",[t._v("如果删除的是最后一个元素，则需要往前遍历，将每一个空的槽设置为 "),s("code",[t._v("emptyRest")]),t._v(" 状态。")]),t._v(" "),s("li",[t._v("如果是 "),s("code",[t._v("indirectkey")]),t._v("、"),s("code",[t._v("indirectelem")]),t._v("，在删除的时候，只会将 "),s("code",[t._v("bucket")]),t._v(" 中的指针置为 "),s("code",[t._v("nil")]),t._v("，对于实际的 "),s("code",[t._v("key")]),t._v(" 和 "),s("code",[t._v("value")]),t._v(" 不会进行处理。（无所谓，GC 会出手）。")])]),t._v(" "),s("h2",{attrs:{id:"map-的扩容实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-的扩容实现"}},[t._v("#")]),t._v(" map 的扩容实现")]),t._v(" "),s("p",[t._v("从上面的讲解中，我们知道，底层存储 "),s("code",[t._v("key/value")]),t._v("  的是 "),s("code",[t._v("bucket")]),t._v("，而 "),s("code",[t._v("bucekt")]),t._v(" 的大小是一段有一定大小的连续内存。 如果我们插入的元素过多，我们初始化时分配的 "),s("code",[t._v("bucket")]),t._v(" 的内存就会放不下了，这个时候 go 的 "),s("code",[t._v("map")]),t._v(" 会有两种方式解决这个问题：")]),t._v(" "),s("ol",[s("li",[t._v("使用溢出桶（在 "),s("code",[t._v("bmap")]),t._v(" 的上再链接一个 "),s("code",[t._v("bmap")]),t._v("，也就是溢出桶，普通桶放不下的时候，就放溢出桶中）")]),t._v(" "),s("li",[t._v("分配新的更大的空间来存放现有的这些键值对。在 go 里面新分配的内存空间将会是原来的 2 倍。")])]),t._v(" "),s("h3",{attrs:{id:"map-扩容的条件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-扩容的条件"}},[t._v("#")]),t._v(" map 扩容的条件")]),t._v(" "),s("p",[s("code",[t._v("map")]),t._v(" 的扩容发生在插入或者修改或者删除 "),s("code",[t._v("key")]),t._v(" 的时候，扩容的条件在 "),s("code",[t._v("mapassign")]),t._v(" 中写了：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 条件：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 没有在扩容")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 超过负载因子")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3. 太多溢出桶")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tooManyOverflowBuckets")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("noverflow"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 判断是否超过负载因子。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" loadFactorNum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketShift")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("loadFactorDen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 判断是否有太多的溢出桶了")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 多的标准是：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// B <= 15 的时候，溢出桶数量大于 2^B 的时候")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// B > 15 的时候，溢出桶的数量大于 2^15 的时候")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tooManyOverflowBuckets")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("noverflow "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果阈值太低，我们会做额外的工作。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果阈值太高，则增长和收缩的 map 会保留大量未使用的内存。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// “太多” 意味着（大约）与常规桶一样多的溢出桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 有关详细信息，请参见incrnoverflow。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// B > 15 => 2 ^ 15，B <= 15 => 2 ^ B")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" noverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br")])]),s("h3",{attrs:{id:"hashgrow-实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hashgrow-实现"}},[t._v("#")]),t._v(" hashGrow 实现")]),t._v(" "),s("p",[s("code",[t._v("hashGrow")]),t._v(" 是被用来分配新的内存空间的，新的内存空间将被用来保存旧的 "),s("code",[t._v("buckets")]),t._v("。"),s("strong",[t._v("需要注意的是，这个函数里面并没有做数据迁移的操作。")]),t._v(" go 的 "),s("code",[t._v("map")]),t._v(" 扩容的时候，数据迁移的方式是渐进式扩容，在我们插入/修改/删除 "),s("code",[t._v("key")]),t._v(" 的时候会迁移 2 个 "),s("code",[t._v("bucket")]),t._v("，这样可以避免性能的瞬时抖动。 我们熟知的 "),s("code",[t._v("redis")]),t._v(" 的扩容过程也是渐进式扩容的。")]),t._v(" "),s("p",[t._v("下面是 "),s("code",[t._v("hashGrow")]),t._v(" 的实现源码：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// hash 扩容（这个方法只是分配了空间，实际上还没有做数据复制的操作）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// t：map 类型元信息")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// h：实际保存键值对的结构体")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容的两种情况：")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1、如果我们达到了负载系数，就要进行 2 倍扩容。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2、否则，如果溢出桶太多，进行等量扩容。")]),t._v("\n   bigger "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 尚未超过负载因子，进行等量扩容")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overLoadFactor")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      bigger "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 等量扩容")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|=")]),t._v(" sameSizeGrow\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录旧的 buckets")]),t._v("\n   oldbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 分配新的内存空间，oldbuckets 将会被渐进式迁移到 newbuckets 中")]),t._v("\n   newbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("makeBucketArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bigger"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// flags 标记有使用旧桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正在迭代的时候扩容")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 先把 h.flags 中的迭代标记位清除。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 最后如果发现 h.flags 中还有迭代标记位，说明在扩容的过程中有新的迭代操作，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 那就把它转移到 oldIterator 中。")]),t._v("\n   flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&^")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iterator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" oldIterator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("iterator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|=")]),t._v(" oldIterator\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 提交扩容操作")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" bigger "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 加上扩容的数量")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" flags\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oldbuckets "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录旧桶")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newbuckets    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指向新的桶数组")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 0 个桶已完成迁移（当前函数只是分配空间，不做迁移）")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("noverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 所有溢出桶没有了（移动到了 oldoverflow）")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录扩容前的溢出桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("throw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"oldoverflow is not nil"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("overflow\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容之后，h.B+bigger >= 4 了，预分配了溢出桶（扩容前没有溢出桶）")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 所以这里要记录溢出桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("new")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mapextra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nextOverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nextOverflow\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 哈希表数据的实际迁移过程是通过 growWork() 和 evacuate() 增量完成的。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br")])]),s("h3",{attrs:{id:"数据迁移的两条线"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据迁移的两条线"}},[t._v("#")]),t._v(" 数据迁移的两条线")]),t._v(" "),s("p",[t._v("go "),s("code",[t._v("map")]),t._v(" 在扩容的时候，数据迁移会有两条线进行：")]),t._v(" "),s("ol",[s("li",[t._v("从第一个 "),s("code",[t._v("bucket")]),t._v(" 开始迁移。")]),t._v(" "),s("li",[t._v("插入、修改、删除的时候，"),s("code",[t._v("key")]),t._v(" 的哈希值定位到的 "),s("code",[t._v("bucket")]),t._v(" 会被迁移。")])]),t._v(" "),s("p",[t._v("具体如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/24.webp",alt:"map_7_1.png"}})]),t._v(" "),s("blockquote",[s("p",[t._v("如果已经被迁移，则不再需要迁移。")])]),t._v(" "),s("p",[t._v("这样一来就可以保证在一定的操作次数之后，全部 "),s("code",[t._v("bucket")]),t._v(" 都被迁移。就算你每次插入、修改、删除都是同一个 "),s("code",[t._v("key")]),t._v("（也就是同一个 "),s("code",[t._v("bucket")]),t._v("）， 我们第一条线的迁移都会在每次写操作的时候，迁移一个 "),s("code",[t._v("bucket")]),t._v("。这样无论如何，写操作到了一定次数之后，所有的 "),s("code",[t._v("bucket")]),t._v(" 都会被迁移了。")]),t._v(" "),s("h3",{attrs:{id:"什么时候-bucket-迁移之后下标会改变"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#什么时候-bucket-迁移之后下标会改变"}},[t._v("#")]),t._v(" 什么时候 bucket 迁移之后下标会改变？")]),t._v(" "),s("p",[t._v("当然这里说的是增量扩容，如果是等量扩容，"),s("code",[t._v("bucket")]),t._v(" 的下标不会改变。")]),t._v(" "),s("p",[t._v("先说答案："),s("code",[t._v("hash & m")]),t._v(" 的最高位是 1 的时候。")]),t._v(" "),s("p",[t._v("我们知道，在定位 "),s("code",[t._v("bucket")]),t._v(" 的时候是通过 "),s("code",[t._v("hash & m")]),t._v(" 的方式来定位 "),s("code",[t._v("bucket")]),t._v(" 的索引的（具体可以看上面定位 "),s("code",[t._v("key")]),t._v(" 的那一节）， 而 2 倍扩容之后，"),s("code",[t._v("bucket")]),t._v(" 的长度是原来的 2 倍，转换为二进制的时候，就是在原来的基础上多了一位，所以 "),s("code",[t._v("hash & m")]),t._v(" 的结果就会多一位， 而最高的那个二进制位如果是 1，说明 "),s("code",[t._v("hash & m")]),t._v(" 的结果是大于新的 "),s("code",[t._v("bucket")]),t._v(" 数组长度的一半的（"),s("strong",[t._v("也就是比原来的索引都要大")]),t._v("）。 那么会最高位是 1 会比原来的索引会大多少呢？答案是 "),s("code",[t._v("bucket")]),t._v(" 数组的长度的一半（也就是 "),s("code",[t._v("2^(B-1)")]),t._v("）：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/25.webp",alt:"map_7_2.png"}})]),t._v(" "),s("p",[t._v("我们可以再看看之前的那个计算 "),s("code",[t._v("bucket")]),t._v(" 索引的图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/26.webp",alt:"map_7_3.png"}})]),t._v(" "),s("p",[t._v("我们会发现，当 "),s("code",[t._v("B = 3")]),t._v(" 的时候，不管 "),s("code",[t._v("hash")]),t._v(" 是什么，"),s("code",[t._v("hash & m")]),t._v(" 的结果都是 "),s("code",[t._v("0~7")]),t._v("。 而只有当 "),s("code",[t._v("B = 4")]),t._v(" 的时候，"),s("code",[t._v("hash & m")]),t._v(" 的结果才有可能落入 "),s("code",[t._v("8~15")]),t._v(" 范围内，而且只有 "),s("code",[t._v("hash & m")]),t._v(" 的最高位是 1 的时候才有可能。")]),t._v(" "),s("p",[s("strong",[t._v("所以结论是，当 "),s("code",[t._v("hash & m")]),t._v(" 的最高位是 1 的时候，"),s("code",[t._v("bucket")]),t._v(" 的下标就会改变。")]),t._v(" 而 "),s("code",[t._v("hash % m")]),t._v(" 的其他位跟之前是一样的，所以下标增加的范围其实就是 "),s("code",[t._v("2^(B - 1)")]),t._v("，也就是旧的 "),s("code",[t._v("buckets")]),t._v(" 的个数。")]),t._v(" "),s("h3",{attrs:{id:"bucket-迁移图解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bucket-迁移图解"}},[t._v("#")]),t._v(" bucket 迁移图解")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/27.webp",alt:"map_7_4.png"}})]),t._v(" "),s("p",[t._v("说明：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("oldbuckets")]),t._v(" 是迁移前的桶，"),s("code",[t._v("buckets")]),t._v(" 是迁移后的桶（也就是当前的 "),s("code",[t._v("h.buckets")]),t._v("）。")]),t._v(" "),s("li",[s("code",[t._v("hash & m")]),t._v(" 为 "),s("code",[t._v("0xxx")]),t._v(" 的时候，会迁移到 "),s("code",[t._v("x")]),t._v(" 这个 "),s("code",[t._v("bucket")]),t._v(" 中。")]),t._v(" "),s("li",[s("code",[t._v("hash & m")]),t._v(" 为 "),s("code",[t._v("1xxx")]),t._v(" 的时候，会迁移到 "),s("code",[t._v("x + 2^(B-1)")]),t._v(" 这个 "),s("code",[t._v("bucket")]),t._v(" 中（也就是 "),s("code",[t._v("y")]),t._v(" 中），因为 "),s("code",[t._v("1000")]),t._v(" 就是 "),s("code",[t._v("2^(4 - 1)")]),t._v("。")])]),t._v(" "),s("p",[t._v("假设需要迁移的是 "),s("code",[t._v("oldbucket")]),t._v("，下标为 "),s("code",[t._v("3")]),t._v("，那么 "),s("code",[t._v("oldbucket")]),t._v(" 里面的 "),s("code",[t._v("key")]),t._v(" 可能迁移的位置只可能是右边的 "),s("code",[t._v("x")]),t._v(" 和 "),s("code",[t._v("y")]),t._v(" 指向的 "),s("code",[t._v("bucket")]),t._v("。 这取决于 "),s("code",[t._v("oldbucket")]),t._v(" 里面的 "),s("code",[t._v("key")]),t._v(" 哈希值的倒数第 "),s("code",[t._v("4")]),t._v(" 位； 如果是 "),s("code",[t._v("0")]),t._v("，那么就迁移到 "),s("code",[t._v("x")]),t._v(" 指向的 "),s("code",[t._v("bucket")]),t._v("，如果是 "),s("code",[t._v("1")]),t._v("，那么就迁移到 "),s("code",[t._v("y")]),t._v(" 指向的 "),s("code",[t._v("bucket")]),t._v("。")]),t._v(" "),s("p",[s("code",[t._v("oldbucket")]),t._v(" 中所有的 "),s("code",[t._v("key")]),t._v(" 只会迁移到 "),s("code",[t._v("x")]),t._v(" 或 "),s("code",[t._v("y")]),t._v(" 中。同时 "),s("code",[t._v("x")]),t._v(" 和 "),s("code",[t._v("y")]),t._v(" 也只可能有 "),s("code",[t._v("oldbucket")]),t._v(" 的 "),s("code",[t._v("key")]),t._v("，不可能有其他旧的 "),s("code",[t._v("bucket")]),t._v(" 的 "),s("code",[t._v("key")]),t._v("。这是由 "),s("code",[t._v("hash & m")]),t._v(" 可以推断出来的。")]),t._v(" "),s("h3",{attrs:{id:"bucket-迁移源码剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bucket-迁移源码剖析"}},[t._v("#")]),t._v(" bucket 迁移源码剖析")]),t._v(" "),s("p",[s("strong",[t._v("开始之前，我们要记住 "),s("code",[t._v("x")]),t._v(" 和 "),s("code",[t._v("y")]),t._v(" 是怎么来的。")])]),t._v(" "),s("p",[t._v("在开始看代码之前，我们需要明确一点："),s("strong",[t._v("虽然整个哈希表是渐进式迁移的，但是单个 "),s("code",[t._v("bucket")]),t._v(" 的迁移不是渐进式的。")])]),t._v(" "),s("ol",[s("li",[t._v("我们先看看 "),s("code",[t._v("growWork")]),t._v(" 函数：")])]),t._v(" "),s("p",[t._v("这是迁移桶的函数，一次会迁移两个桶。不过实际上并不是严格的两个，因为迁移的函数会先判断桶是否已经被迁移， 如果桶还没有被迁移，才会进行迁移，如果桶已经被迁移则不做任何操作。")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 桶迁移")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：h 需要扩容的 map，t map 类型信息，bucket 旧桶的索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1、迁移当前访问到的桶（mapassign、mapdelete 的时候）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2、继续逐个迁移 bucket，直到迁移完成（这个是从第一个桶开始迁移的）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growWork")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迁移当前访问到的桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("oldbucketmask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续逐个迁移 bucket，直到迁移完成")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br")])]),s("ol",[s("li",[t._v("然后看看 "),s("code",[t._v("evacuate")]),t._v(" 函数：")])]),t._v(" "),s("p",[t._v("这个就是实际做迁移操作的函数。它会根据 "),s("code",[t._v("hash & m")]),t._v(" 的倒数第 "),s("code",[t._v("B")]),t._v(" 位是否为 1 来决定将 "),s("code",[t._v("key")]),t._v(" 迁移到 "),s("code",[t._v("h.buckets")]),t._v(" 的前半部分还是后半部分。")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迁移的目的地（旧桶 -> 目标桶）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// evacuate 中会定义两个这个 evacDst 变量，")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 一个指向 h.buckets 的前半部分，一个指向后半部分。（对应前一个图的 x，y）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迁移的时候，会根据 key 的哈希值的倒数第 4 位来决定迁移到哪个 evacDst 中。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" evacDst "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迁移目的地 bucket")]),t._v("\n   i "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v("            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key/elem 在迁移目标 bucket 里面对应的下标")]),t._v("\n   k unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 目标 bucket 下一个保存 key 的地址指针")]),t._v("\n   e unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 目标 bucket 下一个保存 elem 的地址指针")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容的时候，bucket 迁移的实现")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// oldbucket 需要迁移的旧桶索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldbucket "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 指向旧桶")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldbucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容之前的桶的数量")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// oldbucket+newbit 对应 y，oldbucket 对应 x")]),t._v("\n   newbit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("noldbuckets")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 b 尚未迁移，则进行迁移")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuated")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// xy 包含 x 和 y（低和高）迁移目的地。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迁移的时候，在 h.buckets 中，前 noldbuckets 个桶就是 x，后 noldbuckets 个桶就是代表 y。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" xy "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("evacDst\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// x 存储了新桶的地址")]),t._v("\n      x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("xy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// x 指向 oldbucket 可能迁移到的新桶（h.buckets 的前半部分）")]),t._v("\n      x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldbucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// x 桶中下一个用来保存旧桶的 key 的地址")]),t._v("\n      x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// x 桶中下一个用来保存旧桶的 elem 的地址")]),t._v("\n      x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果不是等量扩容（有可能会迁移到 oldbucket+newbit 的位置上）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sameSizeGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("xy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// y 指向增量空间上的第 oldbucket+newbit 个位置")]),t._v("\n         y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldbucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("newbit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// y 桶中下一个保存旧桶 key 的地址")]),t._v("\n         y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// y 桶中下一个保存旧桶 elem 的地址")]),t._v("\n         y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开始迁移旧桶（同时也会迁移溢出桶）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 旧 bucket 上第一个 key")]),t._v("\n         k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 旧 bucket 上第一个 value")]),t._v("\n         e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历 bucket 的槽")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取需要迁移的 key/elem(k/e) 对，迁移到新桶上(&xy[useY])")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取旧的 tophash")]),t._v("\n            top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 的这个槽是空的")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isEmpty")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("top"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 写入已迁移标记")]),t._v("\n               b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" evacuatedEmpty\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理下一个 key/elem")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 错误")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" minTopHash "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("throw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bad map state"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 复制一份 k")]),t._v("\n            k2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" k\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// k2 指向实际的 key")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               k2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// useY 决定了是迁移到 x 还是 y，如果是等量扩容，那么就是迁移到 x")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" useY "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果不是等量扩容")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sameSizeGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算哈希以做出迁移决定（是否需要将此 key/elem 迁移到桶 x 或桶 y）。")]),t._v("\n               hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("iterator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reflexivekey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 下面这段是原英文注释的翻译（可能不太准确）：")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 key != key（不是一个数字），则散列可能（并且可能）与旧散列完全不同。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 此外，它是不可再现的。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在迭代器存在的情况下，再现性是必需的，因为我们的迁移决策必须与迭代器所做的任何决策相匹配。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 幸运的是，我们可以任意发送这些 key。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 此外，tophash 对于这些类型的 key 没有意义。我们让 tophash 的最低位的决定如何迁移。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 我们为下一个级别重新计算一个新的随机 tophash，这样在多次扩容后，这些 key 将均匀分布在所有桶中。")]),t._v("\n                  useY "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n                  top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tophash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 原理参考上面那个图。")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" hash"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("newbit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 取决于 oldB + 1 位是 0 还是 1")]),t._v("\n                     useY "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" evacuatedX"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" evacuatedY "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" evacuatedX"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" evacuatedY "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("throw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bad evacuatedN"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录旧桶的迁移状态")]),t._v("\n            b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" evacuatedX "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" useY "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// evacuatedX + 1 == evacuatedY")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dst 是迁移的目标 bucket")]),t._v("\n            dst "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("xy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("useY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 目标 bucket 装不下了，使用溢出桶")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" bucketCnt "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建溢出桶")]),t._v("\n               dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("newoverflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dst.k 指向溢出桶的第一个 key 的地址")]),t._v("\n               dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dst.e 指向溢出桶的第一个 elem 的地址")]),t._v("\n               dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 使用 & 运算优化，不用进行边界检查")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录 tophash")]),t._v("\n            dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mask dst.i as an optimization, to avoid a bounds check")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将旧的 key/elem 复制到 dst 指向的槽")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 的 key 保存的是指针")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 修改实际存储 key 的内存")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" k2 "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// copy pointer")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 修改 bucket 中保存 key 的内存")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("typedmemmove")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// copy elem")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 的 elem 保存的是指针")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 修改实际存储 elem 的内存")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 修改 bucket 中保存 elem 的内存")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("typedmemmove")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 目标桶的元素个数 +1")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// dst 指向下一个空的槽（slot/cell）")]),t._v("\n            dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这些更新可能会将这些指针推到 key 或 elem 数组的末尾。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这没关系，因为我们在桶的末端有溢出桶指针，以防止指针指向桶的末端。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果指向数组末尾，在下次迁移的时候，会创建溢出桶。")]),t._v("\n            dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 上面有判断 dst.i == bucketCnt，所以这里不会溢出")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 取消链接溢出桶并清除 key/elem 以帮助 GC。（清除旧桶的内存）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("oldIterator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ptrdata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldbucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tophash 状态不能清除。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 但是 key/elem 都可以清除。")]),t._v("\n         ptr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         n "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" dataOffset\n         "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("memclrHasPointers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 刚刚迁移的桶，就是顺序迁移的下一个桶，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 则需要更新 nevacuate 字段，表示已经迁移了多少个桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" oldbucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("advanceEvacuationMark")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newbit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br"),s("span",{staticClass:"line-number"},[t._v("123")]),s("br"),s("span",{staticClass:"line-number"},[t._v("124")]),s("br"),s("span",{staticClass:"line-number"},[t._v("125")]),s("br"),s("span",{staticClass:"line-number"},[t._v("126")]),s("br"),s("span",{staticClass:"line-number"},[t._v("127")]),s("br"),s("span",{staticClass:"line-number"},[t._v("128")]),s("br"),s("span",{staticClass:"line-number"},[t._v("129")]),s("br"),s("span",{staticClass:"line-number"},[t._v("130")]),s("br"),s("span",{staticClass:"line-number"},[t._v("131")]),s("br"),s("span",{staticClass:"line-number"},[t._v("132")]),s("br"),s("span",{staticClass:"line-number"},[t._v("133")]),s("br"),s("span",{staticClass:"line-number"},[t._v("134")]),s("br"),s("span",{staticClass:"line-number"},[t._v("135")]),s("br"),s("span",{staticClass:"line-number"},[t._v("136")]),s("br"),s("span",{staticClass:"line-number"},[t._v("137")]),s("br"),s("span",{staticClass:"line-number"},[t._v("138")]),s("br"),s("span",{staticClass:"line-number"},[t._v("139")]),s("br"),s("span",{staticClass:"line-number"},[t._v("140")]),s("br"),s("span",{staticClass:"line-number"},[t._v("141")]),s("br"),s("span",{staticClass:"line-number"},[t._v("142")]),s("br"),s("span",{staticClass:"line-number"},[t._v("143")]),s("br"),s("span",{staticClass:"line-number"},[t._v("144")]),s("br"),s("span",{staticClass:"line-number"},[t._v("145")]),s("br"),s("span",{staticClass:"line-number"},[t._v("146")]),s("br"),s("span",{staticClass:"line-number"},[t._v("147")]),s("br"),s("span",{staticClass:"line-number"},[t._v("148")]),s("br"),s("span",{staticClass:"line-number"},[t._v("149")]),s("br"),s("span",{staticClass:"line-number"},[t._v("150")]),s("br"),s("span",{staticClass:"line-number"},[t._v("151")]),s("br"),s("span",{staticClass:"line-number"},[t._v("152")]),s("br"),s("span",{staticClass:"line-number"},[t._v("153")]),s("br"),s("span",{staticClass:"line-number"},[t._v("154")]),s("br"),s("span",{staticClass:"line-number"},[t._v("155")]),s("br"),s("span",{staticClass:"line-number"},[t._v("156")]),s("br"),s("span",{staticClass:"line-number"},[t._v("157")]),s("br"),s("span",{staticClass:"line-number"},[t._v("158")]),s("br"),s("span",{staticClass:"line-number"},[t._v("159")]),s("br"),s("span",{staticClass:"line-number"},[t._v("160")]),s("br"),s("span",{staticClass:"line-number"},[t._v("161")]),s("br")])]),s("ol",[s("li",[s("code",[t._v("advanceEvacuationMark")]),t._v(" 的作用是更新 "),s("code",[t._v("nevacuate")]),t._v(" 字段，表示已经迁移了多少个桶。")])]),t._v(" "),s("p",[t._v("我们上面说了，哈希表扩容的时候，会有两条线，"),s("code",[t._v("advanceEvacuationMark")]),t._v(" 就是处理顺序迁移的那条线，让 "),s("code",[t._v("nevacuate")]),t._v(" 指向下一个未迁移的桶。 为什么需要做这个处理呢？这是因为另外一条线的迁移是随机的，访问到哪个桶就迁移哪个桶，这就导致了，顺序迁移的那条线，在将 "),s("code",[t._v("nevacuate")]),t._v(" 指向下一个桶的时候，其实下一个桶是已经迁移了的，我们下次顺序迁移的时候肯定不需要迁移这个桶。 那么解决办法就是，继续向后查找，找到第一个未迁移的桶。")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录迁移进度（从顺序迁移的位置往后遍历，保证 nevacuate 指向下一个尚未迁移的桶）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：h 需要扩容的 map，t map 类型信息，newbit 是旧桶的数量")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("advanceEvacuationMark")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newbit "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// nevacuate 索引加 1")]),t._v("\n   h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 往后找一个未迁移的桶（最多遍历 1024 个桶）。")]),t._v("\n   stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" newbit "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newbit\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 向后遍历，找到第一个未迁移的桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketEvacuated")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这意味着所有旧桶都迁移完了")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" newbit "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 扩容已经完成。释放旧的普通桶数组。")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 也可以丢弃旧的溢出桶。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果它们仍然被迭代器引用，那么迭代器将保存指向切片的指针。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（但是 h 不再需要保存指向切片的指针）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 移除等量扩容标志")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&^=")]),t._v(" sameSizeGrow\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br")])]),s("p",[t._v("这里需要注意的是下面几行代码：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[t._v("stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nevacuate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" newbit "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    stop "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newbit\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("我们在将 "),s("code",[t._v("nevacuate")]),t._v(" 加上 1 之后，还会继续往后遍历 1024 个 bucket，如果 bucket 已迁移，则将 "),s("code",[t._v("nevacuate")]),t._v(" 加 1。")]),t._v(" "),s("p",[t._v("如果没有这个操作会怎样？那就意味着可能有很多的 bucket 都已经迁移了，但是顺序迁移的位置（"),s("code",[t._v("nevacuate")]),t._v("）还没有更新， 这样可能会导致顺序迁移的位置每次都指向了已迁移的 "),s("code",[t._v("bucket")]),t._v("。 最终导致，迁移的时候，只迁移了访问到的 "),s("code",[t._v("bucket")]),t._v("，而没有迁移顺序迁移位置上的那个 "),s("code",[t._v("bucket")]),t._v("。")]),t._v(" "),s("p",[s("strong",[t._v("也就是说，每次迁移的时候只会迁移 1 个 "),s("code",[t._v("bucket")]),t._v("，而不是 2 个，这样一来 "),s("code",[t._v("growWork")]),t._v(" 需要调用的次数比原来更多，也就是说，需要写操作次数更多才能完成全部 "),s("code",[t._v("bucket")]),t._v(" 的迁移")]),t._v("。")]),t._v(" "),s("p",[t._v("这个函数做的事情可以表示成下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/28.webp",alt:"map_7_5.png"}})]),t._v(" "),s("p",[t._v("在这个图中，"),s("code",[t._v("nevacuate")]),t._v(" 一开始是 "),s("code",[t._v("1")]),t._v("，然后因为 "),s("code",[t._v("3")]),t._v(" 这个 "),s("code",[t._v("bucket")]),t._v(" 在这次 "),s("code",[t._v("growWork")]),t._v(" 中已经迁移了， "),s("code",[t._v("nevacuate")]),t._v(" 如果要指向下一个未迁移的 "),s("code",[t._v("bucket")]),t._v(" 的话，就要跳过之前已经迁移的 "),s("code",[t._v("2")]),t._v("，以及本次 "),s("code",[t._v("growWork")]),t._v(" 中已经迁移的 "),s("code",[t._v("3")]),t._v("， 所以最终 "),s("code",[t._v("nevacuate")]),t._v(" 指向了 "),s("code",[t._v("4")]),t._v("，也就是下一个未迁移的 "),s("code",[t._v("bucket")]),t._v("。")]),t._v(" "),s("h3",{attrs:{id:"等量扩容的效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#等量扩容的效果"}},[t._v("#")]),t._v(" 等量扩容的效果")]),t._v(" "),s("p",[t._v("在上面我们讲解的时候，其实已经假设了扩容是增量扩容（2 倍扩容），但实际上还有一种扩容方式，就是等量扩容。 等量扩容的时候，扩容前后的 "),s("code",[t._v("bucket")]),t._v(" 其实数量是一样的，那么为什么还要进行扩容呢？")]),t._v(" "),s("p",[t._v("这是因为，溢出桶太多了，数据非常零散地分布在了很多的溢出桶中，这样会导致 "),s("code",[t._v("bucket")]),t._v(" 中很多槽都是空的， 这样一来，进行查找、修改、删除的时候，需要遍历很多的溢出桶，这样会导致性能下降。如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/29.webp",alt:"map_7_6.png"}})]),t._v(" "),s("p",[t._v("这个图中，我们假设要查找的 "),s("code",[t._v("key")]),t._v(" 所在的普通桶以及前两个溢出桶都是空的，又或者 "),s("code",[t._v("key")]),t._v(" 不在前面三个桶中，那只有遍历到最后一个溢出桶的时候才能找到我们要查找的 "),s("code",[t._v("key")]),t._v("。为了针对这种键值对数量没有达到扩容的阈值，但是溢出桶太多的情况，Go 语言提供了等量扩容的方式。")]),t._v(" "),s("p",[t._v("在等量扩容的时候，会将所有的溢出桶都迁移到新的 "),s("code",[t._v("bucket")]),t._v(" 中，这样一来，"),s("code",[t._v("bucket")]),t._v(" 中的槽就会被填满，而溢出桶也可能不再需要。")]),t._v(" "),s("p",[t._v("最后，针对上图的情况，"),s("code",[t._v("key = foo")]),t._v(" 会被迁移到普通桶中，这样在查找的时候，只需要遍历普通桶就可以找到了。 当然，实际中的情况是，对于零散分布在多个溢出桶中的键值对，会被逐个往前挪，最终效果就是，桶中没有空的槽，除了最后一个 "),s("code",[t._v("key")]),t._v(" 以后的槽。")]),t._v(" "),s("p",[t._v("大家可以结合下图想象一下：")]),t._v(" "),s("p",[t._v("当然下图只是描述了一下部分 "),s("code",[t._v("key")]),t._v("，如果 "),s("code",[t._v("key")]),t._v(" 分布。实际上 "),s("code",[t._v("key")]),t._v(" 在触发等量扩容的情况下，是零散地分布在不同的 "),s("code",[t._v("bucket")]),t._v(" 中的（包括溢出桶）。")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/30.webp",alt:"map_7_7.png"}})]),t._v(" "),s("h2",{attrs:{id:"map-的迭代实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-的迭代实现"}},[t._v("#")]),t._v(" map 的迭代实现")]),t._v(" "),s("p",[t._v("go 的 "),s("code",[t._v("map")]),t._v(" 迭代的时候，我们会发现，返回结果的顺序并不固定，这是因为 "),s("code",[t._v("map")]),t._v(" 的迭代是无序的。 在 "),s("code",[t._v("map")]),t._v(" 遍历的时候，每次都会从一个随机的 "),s("code",[t._v("bucket")]),t._v(" 开始遍历，而且选了一个 "),s("code",[t._v("bucket")]),t._v(" 之后， 还会从 "),s("code",[t._v("bucket")]),t._v(" 中随机选择一个槽开始遍历，这样一来，每次遍历的结果都是不一样的。")]),t._v(" "),s("h3",{attrs:{id:"map-迭代器数据结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-迭代器数据结构"}},[t._v("#")]),t._v(" map 迭代器数据结构")]),t._v(" "),s("p",[t._v("迭代器的功能：记录要遍历的 "),s("code",[t._v("map")]),t._v("，以及当前遍历到的 "),s("code",[t._v("bucket")]),t._v(" 以及槽的索引，以便进行下一次遍历。")]),t._v(" "),s("p",[t._v("go 的 "),s("code",[t._v("map")]),t._v(" 迭代器的数据结构如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 哈希迭代结构。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" hiter "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 必须排在第一位。 写入 nil 表示迭代结束")]),t._v("\n   key unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 必须在第二个位置（参见 cmd/compile/internal/walk/range.go）。")]),t._v("\n   elem unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer\n   t    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype       "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map 的类型信息，包括 key、elem 的类型等信息")]),t._v("\n   h    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 需要迭代的 hmap")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// hash_iter 初始化时的 bucket 指针")]),t._v("\n   buckets unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前正在遍历的 bucket")]),t._v("\n   bptr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 保持 hmap.buckets 的溢出桶存活")]),t._v("\n   overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 保持 hmap.oldbuckets 的溢出桶存活")]),t._v("\n   oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 迭代开始位置（随机选择的 bucket）")]),t._v("\n   startBucket "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在迭代期间开始的桶内偏移量（应该足够大以容纳 bucketCnt-1）")]),t._v("\n   offset "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 已经从桶数组的末尾环绕到开始")]),t._v("\n   wrapped     "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v("\n   B           "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 就是当前遍历的 hmap 的那个 B")]),t._v("\n   i           "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint8")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前遍历的 bucket 内 key 的索引")]),t._v("\n   bucket      "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前遍历的 bucket")]),t._v("\n   checkBucket "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br")])]),s("p",[t._v("几点注意的：")]),t._v(" "),s("ol",[s("li",[t._v("全部键值对遍历完的时候，"),s("code",[t._v("key")]),t._v(" 会被置为 "),s("code",[t._v("nil")]),t._v("，这样一来，我们就可以通过 "),s("code",[t._v("key")]),t._v(" 是否为 "),s("code",[t._v("nil")]),t._v(" 来判断是否遍历完了。（当然这个不用开发者来判断，"),s("code",[t._v("for...range")]),t._v(" 底层已经帮我们做了这个判断）。")]),t._v(" "),s("li",[s("code",[t._v("hiter")]),t._v(" 结构体保存了当前正在迭代的 "),s("code",[t._v("bucket")]),t._v("（"),s("code",[t._v("bptr")]),t._v("）、"),s("code",[t._v("bucket")]),t._v(" 中的 "),s("code",[t._v("key")]),t._v(" 的索引（"),s("code",[t._v("i")]),t._v("）等信息，这样一来，我们就可以通过这些信息来确定下一个 "),s("code",[t._v("key")]),t._v(" 的位置。")])]),t._v(" "),s("h3",{attrs:{id:"迭代器的初始化实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#迭代器的初始化实现"}},[t._v("#")]),t._v(" 迭代器的初始化实现")]),t._v(" "),s("p",[t._v("go 的 "),s("code",[t._v("map")]),t._v(" 初始化是通过 "),s("code",[t._v("runtime.mapiterinit")]),t._v(" 来实现的，这个函数的实现如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mapiterinit 初始化用于 range 遍历 map 的 hiter 结构。（初始化 hiter）")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 'it' 指向的 hiter 结构由编译器顺序传递在堆栈上分配，或由 reflect_mapiterinit 在堆上分配。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 两者都需要将 hiter 置零，因为结构包含指针。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapiterinit")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("maptype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" it "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hiter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// hiter 记录 map 的类型信息")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 map 是空的直接返回")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 个人猜测：内存对齐判断，这个由编译器决定的")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Sizeof")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hiter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("goarch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PtrSize "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("throw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hash_iter size incorrect"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// see cmd/compile/internal/reflectdata/reflect.go")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// it 关联上 map")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取桶状态的快照")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前的 buckets")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 里面没有包含指针")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ptrdata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 分配当前切片并记住指向当前切片和旧切片的指针。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这将保持所有相关的溢出桶处于活动状态，即使在迭代时表增长和/或溢出桶添加到表中。")]),t._v("\n      h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createOverflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("overflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("overflow\n      it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldoverflow "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldoverflow\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   \n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 决定从哪里开始遍历。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 策略：随机选定一个 bucket，然后从该 bucket 开始遍历。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 生成随机数")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" r "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uintptr")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("bucketCntBits "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      r "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastrand64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      r "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastrand")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// r => 扫描的入口（随机选的 bucket）")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" r "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 随机定位的 bucket 中的槽。")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("r "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录当前扫描的 bucket")]),t._v("\n   it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startBucket\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记住我们有一个迭代器。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 可以与另一个 mapiteinit() 同时运行。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" old "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" old"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iterator"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("oldIterator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" iterator"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("oldIterator "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      atomic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Or8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" iterator"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("oldIterator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开始遍历")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapiternext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br")])]),s("p",[t._v("这个函数主要功能是初始化迭代器，我们最需要关心的是，这个函数里面会生成一个随机数，然后通过这个随机数来决定从哪一个 "),s("code",[t._v("bucket")]),t._v(" 开始遍历， 以及从 "),s("code",[t._v("bucket")]),t._v(" 中的哪一个槽开始遍历（也是随机的）。")]),t._v(" "),s("h3",{attrs:{id:"map-遍历图解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#map-遍历图解"}},[t._v("#")]),t._v(" map 遍历图解")]),t._v(" "),s("p",[t._v("那为什么从随机定位的 "),s("code",[t._v("bucket")]),t._v(" 以及随机定位的 "),s("code",[t._v("key")]),t._v(" 就可以实现遍历呢？其实很简单，如果看过我之前写的 《go chan 设计与实现》的话， 就会知道 "),s("code",[t._v("chan")]),t._v(" 的实现中是通过数组来实现环形队列的。而我们可以借助环形队列的特性来理解 "),s("code",[t._v("map")]),t._v(" 的遍历。遍历到最后一个 "),s("code",[t._v("bucket")]),t._v(" 之后， 下一个 "),s("code",[t._v("bucket")]),t._v(" 就是第一个 "),s("code",[t._v("bucket")]),t._v("，这样就实现了环形遍历。同样的，遍历到最后一个 "),s("code",[t._v("key")]),t._v(" 之后，下一个 "),s("code",[t._v("key")]),t._v(" 就是第一个 "),s("code",[t._v("key")]),t._v("，这样也实现了环形遍历。")]),t._v(" "),s("p",[t._v("我们需要做的就是，在遍历开始的时候，记录第一个 "),s("code",[t._v("bucket")]),t._v("，然后每次遍历 "),s("code",[t._v("bucket")]),t._v(" 的时候， 比较当前的 "),s("code",[t._v("bucket")]),t._v(" 是否是第一个 "),s("code",[t._v("bucket")]),t._v("，是的话，意味着遍历结束了。 同样的，对于 "),s("code",[t._v("bucket")]),t._v(" 内 "),s("code",[t._v("key")]),t._v(" 的遍历也是。")]),t._v(" "),s("p",[t._v("不过，在实际实现中，"),s("code",[t._v("key")]),t._v(" 有点不一样，"),s("code",[t._v("key")]),t._v(" 的遍历是通过将 "),s("code",[t._v("i")]),t._v(" 从 "),s("code",[t._v("0")]),t._v(" 遍历到 "),s("code",[t._v("7")]),t._v("，对于每一个 "),s("code",[t._v("i")]),t._v("，加上 "),s("code",[t._v("it.offset")]),t._v("，然后对 "),s("code",[t._v("8")]),t._v(" 取模， 这样就可以实现环形遍历了，代码如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 桶内第 i 个元素")]),t._v("\n   offi "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("具体遍历过程如下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/31.webp",alt:"map_8_1.png"}})]),t._v(" "),s("h3",{attrs:{id:"发生在扩容期间的遍历"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#发生在扩容期间的遍历"}},[t._v("#")]),t._v(" 发生在扩容期间的遍历")]),t._v(" "),s("p",[t._v("go 的 "),s("code",[t._v("map")]),t._v(" 设计中，是不允许在迭代的时候进行插入、修改、删除的，但只是在获取下一个键值对的时候不允许， 在迭代器获取了键值对之后，就算还没有全部遍历完 "),s("code",[t._v("map")]),t._v(" 的所有元素，还是可以允许做插入、修改、删除操作的。 这样一来，有可能会出现一些奇怪的现象，比如插入的 "),s("code",[t._v("key")]),t._v(" 遍历不出来，或者遍历出来的 "),s("code",[t._v("key")]),t._v(" 有重复等等。这是需要开发者注意的地方。")]),t._v(" "),s("p",[t._v("另外，迭代可以发生在扩容的过程中，但是扩容其实对迭代其实是没有什么影响的。因为迭代的时候会做一些判断尽量保证所有 "),s("code",[t._v("key")]),t._v(" 都能被遍历到。 但不能保证我们对 "),s("code",[t._v("map")]),t._v(" 做了写操作后依然可以全部 "),s("code",[t._v("key")]),t._v(" 都遍历。")]),t._v(" "),s("p",[t._v("在遍历的过程中，如果 "),s("code",[t._v("map")]),t._v(" 发生了扩容，那么遍历的过程就会变得复杂一些。因为在扩容的过程中，"),s("code",[t._v("map")]),t._v(" 会新建一个 "),s("code",[t._v("bucket")]),t._v("， 然后将原来的 "),s("code",[t._v("bucket")]),t._v(" 中的 "),s("code",[t._v("key")]),t._v(" 重新散列到新的 "),s("code",[t._v("bucket")]),t._v(" 中。所以在遍历的过程中，如果发现当前的 "),s("code",[t._v("bucket")]),t._v(" 已经发生了扩容， 需要做一些判断，比如：")]),t._v(" "),s("ol",[s("li",[t._v("如果发现 "),s("code",[t._v("bucket")]),t._v(" 还没有迁移，则从 "),s("code",[t._v("oldbuckets")]),t._v(" 中遍历。")]),t._v(" "),s("li",[t._v("如果发现 "),s("code",[t._v("bucket")]),t._v(" 在迁移之后索引跟原来的不一样，则跳过。")])]),t._v(" "),s("p",[t._v("具体可以参考下图：")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/go/map/32.webp",alt:"map_8_2.png"}})]),t._v(" "),s("p",[t._v("这里假设的条件是：旧桶个数为 "),s("code",[t._v("4")]),t._v("，增量扩容后，新桶个数为 "),s("code",[t._v("8")]),t._v("。"),s("code",[t._v("hiter")]),t._v(" 当前迭代的是新桶。")]),t._v(" "),s("p",[t._v("说明：")]),t._v(" "),s("ol",[s("li",[s("code",[t._v("h.oldbuckets")]),t._v(" 指向了还没迁移完的桶，"),s("code",[t._v("h.buckets")]),t._v(" 是当前的桶。")]),t._v(" "),s("li",[s("code",[t._v("hiter")]),t._v(" 迭代器要迭代的是新的桶。迭代器初始化的时候正在进行 2 倍扩容。")]),t._v(" "),s("li",[s("code",[t._v("checkBucket")]),t._v(" 是下一个要遍历的桶（索引为 "),s("code",[t._v("1")]),t._v("），图中的情况是，这个桶还没有被迁移。所以需要从 "),s("code",[t._v("h.oldbuckets")]),t._v(" 中读取。")]),t._v(" "),s("li",[s("code",[t._v("checkBucket")]),t._v(" 中的 "),s("code",[t._v("key")]),t._v(" 有可能会迁移到 "),s("code",[t._v("h.buckets")]),t._v(" 中的 "),s("code",[t._v("1")]),t._v(" 或者 "),s("code",[t._v("5")]),t._v(" 位置。（具体可以看上面桶迁移的实现那一节）")]),t._v(" "),s("li",[t._v("如果 "),s("code",[t._v("key")]),t._v(" 是要被迁移到 "),s("code",[t._v("5")]),t._v(" 中的话，那么遍历的时候会跳过，因为后面会遍历到 "),s("code",[t._v("5")]),t._v(" 中的 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("li",[t._v("对于第 5 点，在遍历 "),s("code",[t._v("5")]),t._v(" 这个 "),s("code",[t._v("bucket")]),t._v(" 的时候，由于我们是使用当前遍历的 "),s("code",[t._v("bucket")]),t._v(" 的下标结合旧桶的长度计算在旧桶中的下标的，所以还是可以取得到旧桶，然后遍历的时候取出那些应该迁移到 "),s("code",[t._v("5")]),t._v(" 这个 "),s("code",[t._v("bucket")]),t._v(" 的 "),s("code",[t._v("key")]),t._v("，对于那些应该要迁移到 "),s("code",[t._v("1")]),t._v(" 的 "),s("code",[t._v("key")]),t._v(" 则跳过。")]),t._v(" "),s("li",[t._v("下一个要遍历的桶的索引为 "),s("code",[t._v("2")]),t._v("。")])]),t._v(" "),s("p",[t._v("对于第 6 点桶索引计算的特别说明，如果是增量扩容，计算 "),s("code",[t._v("bucket")]),t._v(" 的下标方式如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 是当前要遍历的 bucket 的下标")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// it.h.oldbucketmask() 是旧桶的 B 的掩码")]),t._v("\noldbucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("oldbucketmask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("当然如果这个桶已经迁移，那么还是会从新桶遍历（也就是 "),s("code",[t._v("bucket & it.h.oldbucketmask()")]),t._v(" 里的 "),s("code",[t._v("bucket")]),t._v(" 本身）。")]),t._v(" "),s("h3",{attrs:{id:"键值对遍历源码剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#键值对遍历源码剖析"}},[t._v("#")]),t._v(" 键值对遍历源码剖析")]),t._v(" "),s("p",[s("code",[t._v("map")]),t._v(" 中实现遍历的函数是 "),s("code",[t._v("mapiternext")]),t._v("，这个函数做的事情，也就是上面两个图描述的遍历过程，代码如下：")]),t._v(" "),s("div",{staticClass:"language-go line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数：迭代器实例")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapiternext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("hiter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取底层的 hmap 实例")]),t._v("\n   h "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("h\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 正在插入、修改、删除 key 但时候，不能获取下一个 key，")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意：这不能保证插入、修改、删除之后，进行迭代。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("hashWriting "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fatal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"concurrent map iteration and map write"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("t           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// *maptype")]),t._v("\n   bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前遍历到的 bucket 下标（int 类型）")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bptr        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前 bucket 的指针（实际的 bucket，bmap 指针类型）")]),t._v("\n   i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迭代器当前遍历到的位置（bucket 内 key 的位置）")]),t._v("\n   checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkBucket "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个用来判断是否是增量扩容的")]),t._v("\n\nnext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意：下面的 if 的功能是，获取下一个桶。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果 b 是 nil，有以下两种情况：")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// a. 第一次遍历，还没有遍历到任何 bucket。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b. 遍历完最后一个 bucket 了。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 已经迭代完了，直接退出函数")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wrapped "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// for...range 查看到 key 是 nil 会中止迭代")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果正在扩容")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("growing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迭代器是在扩容过程中启动的，扩容尚未完成。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果我们正在查看的存储桶尚未迁移，")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 那么我们需要遍历旧存储桶，同时只返回将迁移到此存储桶的数据。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 那些需要迁移到另一个下标的桶则跳过。")]),t._v("\n         oldbucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("oldbucketmask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取旧桶")]),t._v("\n         b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("oldbuckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldbucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("evacuated")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 旧桶还没有迁移")]),t._v("\n            checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bucket\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 已经迁移了，获取新桶")]),t._v("\n            b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" noCheck\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 并没有在扩容，获取新的桶")]),t._v("\n         b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("bmap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buckets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" noCheck\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// bucket 指向了下一个要迭代的桶的下标")]),t._v("\n      bucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 判断当前遍历的桶是否到最后一个桶了")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketShift")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wrapped "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 已经从第一个随机定位的 bucket 遍历到最后一个 bucket 了，下一个应该是第一个 bucket 了")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开始遍历新的 bucket 的时候，重置 i")]),t._v("\n      i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开始遍历桶内的键值对")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" bucketCnt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 计算桶内键值对的下标（从随机的 it.offset 下标开始遍历）")]),t._v("\n      offi "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bucketCnt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果槽是空的，或者 key 已经迁移，则跳过。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isEmpty")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" evacuatedEmpty "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 桶内第 i 个元素的 key 的指针")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取 key 或 elem 的解析前面的小节有详细的解释了，不再赘述。")]),t._v("\n      k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectkey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         k "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 桶内第 i 个元素的 elem 的指针")]),t._v("\n      e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Pointer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataOffset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("bucketCnt"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keysize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elemsize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 增量扩容的 key 判断")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 需要判断迁移之后的 key 落入的是 h.buckets 的前半部分还是后半部分（x 还是 y）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 具体看上面的迁移实现。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" noCheck "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sameSizeGrow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reflexivekey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 是可比较的")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果这个 key 将会被迁移到 h.buckets 的后半部分，跳过它")]),t._v("\n            hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hasher")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hash0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" hash"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bucketMask")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" checkBucket "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 对于不可比较的 key，")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 是由 tophash 的最低位来决定迁移到前半部分还是后半部分的。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 取 checkBucket 的最高位来比较，因为 checkBucket 的最高位决定了")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前遍历的 bucket 是上半部分还是后半部分的 bucket。")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" checkBucket"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("B"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uintptr")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果当前的 key 没有落入当前遍历的 bucket，则跳过它")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      \n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" evacuatedX "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tophash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("offi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" evacuatedY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reflexivekey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("equal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 上面的判断：")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1、表示 key 还没有迁移。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2、或者，key 是不可比较的。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 则直接返回")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" k\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("indirectelem")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            e "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("unsafe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" e\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 自迭代器启动以来，哈希表已扩容。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 已经被迁移到其他地方。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 检查当前哈希表中的数据。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 此代码处理已删除、更新或删除并重新插入 key 的情况。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意：我们需要重新标记 key，因为它可能已更新为 equal() 但不是相同的 key（例如 +0.0 vs -0.0）。")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取当前遍历到的 key/elem。")]),t._v("\n         rk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" re "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapaccessK")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" rk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// key 已经被删除了，继续遍历下一个 key")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 外部是通过 it 的 key/elem 来获取当前遍历到的键值对的")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rk\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录当前迭代的 bucket")]),t._v("\n      it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bucket\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历到下一个 bucket 了，更新 bptr")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bptr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// avoid unnecessary write barrier; see issue 14921")]),t._v("\n         it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bptr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 迭代器的 i 指向 bucket 内的下一个 key")]),t._v("\n      it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录是否需要检查 key 的标记")]),t._v("\n      it"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkBucket "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" checkBucket\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 找到了键值对（保存在 it.key/it.elem 中了），返回。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mapiternext 外部可以通过 hiter 的 key/elem 属性来获取当前遍历到的 key/val。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历下一个元素的时候，再次调用 mapiternext 函数。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//（无所谓，hiter 会记住迭代到哪里的）")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 也即：每遍历一个元素，调用一次 mapiternext 函数。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前的 bucket 遍历完了，那么继续从溢出桶中查找下一个元素。")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// b 指向溢出桶，迭代溢出桶")]),t._v("\n   b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("overflow")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历下一个桶了，key 从 0 开始遍历")]),t._v("\n   i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 遍历当前 bucket 的溢出桶")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),t._v(" next\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br"),s("span",{staticClass:"line-number"},[t._v("123")]),s("br"),s("span",{staticClass:"line-number"},[t._v("124")]),s("br"),s("span",{staticClass:"line-number"},[t._v("125")]),s("br"),s("span",{staticClass:"line-number"},[t._v("126")]),s("br"),s("span",{staticClass:"line-number"},[t._v("127")]),s("br"),s("span",{staticClass:"line-number"},[t._v("128")]),s("br"),s("span",{staticClass:"line-number"},[t._v("129")]),s("br"),s("span",{staticClass:"line-number"},[t._v("130")]),s("br"),s("span",{staticClass:"line-number"},[t._v("131")]),s("br"),s("span",{staticClass:"line-number"},[t._v("132")]),s("br"),s("span",{staticClass:"line-number"},[t._v("133")]),s("br"),s("span",{staticClass:"line-number"},[t._v("134")]),s("br"),s("span",{staticClass:"line-number"},[t._v("135")]),s("br"),s("span",{staticClass:"line-number"},[t._v("136")]),s("br"),s("span",{staticClass:"line-number"},[t._v("137")]),s("br"),s("span",{staticClass:"line-number"},[t._v("138")]),s("br"),s("span",{staticClass:"line-number"},[t._v("139")]),s("br"),s("span",{staticClass:"line-number"},[t._v("140")]),s("br"),s("span",{staticClass:"line-number"},[t._v("141")]),s("br"),s("span",{staticClass:"line-number"},[t._v("142")]),s("br"),s("span",{staticClass:"line-number"},[t._v("143")]),s("br"),s("span",{staticClass:"line-number"},[t._v("144")]),s("br"),s("span",{staticClass:"line-number"},[t._v("145")]),s("br"),s("span",{staticClass:"line-number"},[t._v("146")]),s("br"),s("span",{staticClass:"line-number"},[t._v("147")]),s("br"),s("span",{staticClass:"line-number"},[t._v("148")]),s("br"),s("span",{staticClass:"line-number"},[t._v("149")]),s("br"),s("span",{staticClass:"line-number"},[t._v("150")]),s("br"),s("span",{staticClass:"line-number"},[t._v("151")]),s("br"),s("span",{staticClass:"line-number"},[t._v("152")]),s("br")])]),s("h2",{attrs:{id:"小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),s("ul",[s("li",[t._v("哈希表相比数组，可以很快速地查找，所以常见的编程语言都会有对应的实现。")]),t._v(" "),s("li",[t._v("哈希冲突有两种解决方法："),s("strong",[t._v("开放地址法")]),t._v("和"),s("strong",[t._v("链表法")]),t._v("，go 里的 "),s("code",[t._v("map")]),t._v(" 使用的是"),s("strong",[t._v("链表法")]),t._v("。")]),t._v(" "),s("li",[t._v("哈希表初始化分配的是比较小的内存，只能存放少量键值对，但是随着我们插入的数据越来越多，哈希表会进行扩容，防止哈希表的读写性能下降。")]),t._v(" "),s("li",[t._v("go 的 "),s("code",[t._v("map")]),t._v(" 扩容有两种方式：键值对太多的时候会进行 2 倍扩容，溢出桶太多会进行等量扩容。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 中使用 "),s("code",[t._v("buckets")]),t._v(" 来存储桶，一个桶里面可以存储 "),s("code",[t._v("8")]),t._v(" 个键值对，一个桶满了的时候，会创建溢出桶来保存多出来的 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 中桶的结构体是 "),s("code",[t._v("bmap")]),t._v("，它里面的会将所有 "),s("code",[t._v("key")]),t._v(" 连续存储，所有的 "),s("code",[t._v("value")]),t._v(" 也会连续存储。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 定位 "),s("code",[t._v("key")]),t._v(" 的时候，会使用哈希值与 "),s("code",[t._v("B")]),t._v(" 的掩码做 "),s("code",[t._v("&")]),t._v(" 运算（我们可以将其理解为一种模运算的另外一种实现），从而得到 "),s("code",[t._v("bucket")]),t._v(" 的下标，然后遍历这个 "),s("code",[t._v("bucket")]),t._v(" 中的每一个槽。先比较 "),s("code",[t._v("tophash")]),t._v("，如果 "),s("code",[t._v("tophash")]),t._v(" 相等再比较 "),s("code",[t._v("key")]),t._v("，如果 "),s("code",[t._v("tophash")]),t._v(" 和 "),s("code",[t._v("key")]),t._v(" 都相等，则表明找到了我们要找的 "),s("code",[t._v("key")]),t._v("。如果这两者有一个不等，继续比较下一个 "),s("code",[t._v("key")]),t._v("。")]),t._v(" "),s("li",[t._v("如果一个 "),s("code",[t._v("bucket")]),t._v(" 中的所有 "),s("code",[t._v("key")]),t._v(" 被遍历完了也没有找到，那么继续从溢出桶中查找。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 读取数据是通过 "),s("code",[t._v("mapaccess1")]),t._v("、"),s("code",[t._v("mapaccess2")]),t._v("、"),s("code",[t._v("mapaccessK")]),t._v(" 实现的，对于整型键值的 "),s("code",[t._v("map")]),t._v(" 有优化的 "),s("code",[t._v("mapaccess")]),t._v(" 实现（对于 "),s("code",[t._v("bmap")]),t._v(" 里键值的访问更加高效）。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 写入和修改数据都是通过 "),s("code",[t._v("mapassign")]),t._v(" 函数实现的，这个函数在找不到 "),s("code",[t._v("key")]),t._v(" 的时候会进行插入操作。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 删除数据是通过 "),s("code",[t._v("mapdelete")]),t._v(" 函数实现的。删除的时候会需要将 "),s("code",[t._v("bucket")]),t._v(" 末尾的所有空的槽的标记更新为 "),s("code",[t._v("emptyRest")]),t._v("。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 扩容的条件有两个：超过负载因子、溢出桶太多。只有在增量扩容的时候，"),s("code",[t._v("key")]),t._v(" 所对应的 "),s("code",[t._v("bucket")]),t._v(" 的下标才有可能发生变化。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 扩容的时候，会迁移当前正在写入、删除的 "),s("code",[t._v("bucket")]),t._v("，同时也会从第一个 "),s("code",[t._v("bucket")]),t._v(" 开始迁移，一次写操作会迁移两个 "),s("code",[t._v("bucket")]),t._v("。这样可以保证在一定的写操作以后，所有 "),s("code",[t._v("bucket")]),t._v(" 都能迁移完成。")]),t._v(" "),s("li",[t._v("等量扩容的时候，"),s("code",[t._v("key")]),t._v(" 在新桶中的 "),s("code",[t._v("bucket")]),t._v(" 下标不变，但是 "),s("code",[t._v("key")]),t._v(" 在桶内的分布会更加地紧凑，从而会提高查找效率。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 的迭代是通过 "),s("code",[t._v("hiter")]),t._v(" 结构体来实现的，迭代的过程中 "),s("code",[t._v("hiter")]),t._v(" 会记录当前的 "),s("code",[t._v("bucket")]),t._v("、"),s("code",[t._v("key")]),t._v("，普通桶迭代完后，迭代溢出桶。"),s("code",[t._v("map")]),t._v(" 的迭代是通过 "),s("code",[t._v("mapiternext")]),t._v(" 函数实现的，每次获取键值对都是通过这个 "),s("code",[t._v("mapiternext")]),t._v(" 函数。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v(" 迭代如果发生在增量扩容的时候，对于未迁移的 "),s("code",[t._v("bucket")]),t._v("，会判断 "),s("code",[t._v("key")]),t._v(" 的 "),s("code",[t._v("bucket")]),t._v(" 是否会发生变化，如果 "),s("code",[t._v("key")]),t._v(" 对应的 "),s("code",[t._v("bucket")]),t._v(" 已经改变，则迭代的时候会跳过。")])])])}),[],!1,null,null,null);s.default=e.exports}}]);