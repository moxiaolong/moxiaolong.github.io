(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{350:function(s,t,n){"use strict";n.r(t);var a=n(8),e=Object(a.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("go 的切片我们都知道可以自动地进行扩容，具体来说就是在切片的容量容纳不下新的元素的时候， 底层会帮我们为切片的底层数组分配更大的内存空间，然后把旧的切片的底层数组指针指向新的内存中：\n"),t("img",{attrs:{src:"/images/go/slice/1.webp",alt:"slice_4_1.png"}})]),s._v(" "),t("blockquote",[t("p",[s._v("基于 Go 1.19。")])]),s._v(" "),t("p",[s._v("目前网上一些关于扩容倍数的文章都是基于相对旧版本的 Go 的，新版本中，现在切片扩容的时候并不是那种准确的小于多少容量的时候就 "),t("code",[s._v("2")]),s._v(" 倍扩容， 大于多少容量的时候就 "),t("code",[s._v("1.25")]),s._v(" 倍扩容，其实这个数值多少不是非常关键的，我们只需要知道的是： "),t("strong",[s._v("在容量较小的时候，扩容的因子更大，容量大的时候，扩容的因子相对来说比较小")]),s._v("。")]),s._v(" "),t("h2",{attrs:{id:"扩容的示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩容的示例"}},[s._v("#")]),s._v(" 扩容的示例")]),s._v(" "),t("p",[s._v("我们先通过一个简单的示例来感受一下切片扩容是什么时候发生的：")]),s._v(" "),t("div",{staticClass:"language-go line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-go"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" slice "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\nfmt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("Println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cap")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nslice "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("append")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nfmt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("Println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cap")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("在这个例子中，"),t("code",[s._v("slice")]),s._v(" 切片初始化的时候，长度和容量都是 "),t("code",[s._v("3")]),s._v("（容量不指定的时候默认等于长度）。 因此切片已经容纳不下新的元素了，在我们往 "),t("code",[s._v("slice")]),s._v(" 中追加一个新的元素的时候， 我们发现，"),t("code",[s._v("slice")]),s._v(" 的长度和容量都变了， 长度增加了 "),t("code",[s._v("1")]),s._v("，而容量变成了原来的 "),t("code",[s._v("2")]),s._v(" 倍。")]),s._v(" "),t("p",[t("img",{attrs:{src:"/images/go/slice/2.webp",alt:"slice_4_2.png"}})]),s._v(" "),t("blockquote",[t("p",[s._v("在 1.18 版本以后，旧的切片容量小于 256 的时候，会进行 2 倍扩容。")])]),s._v(" "),t("h2",{attrs:{id:"实际扩容倍数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实际扩容倍数"}},[s._v("#")]),s._v(" 实际扩容倍数")]),s._v(" "),t("p",[s._v("其实最新的扩容规则在 1.18 版本中就已经发生改变了，具体可以参考一下这个 "),t("code",[s._v("commit")]),s._v("： "),t("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fgolang%2Fgo%2Fcommit%2F2dda92ff6f9f07eeb110ecbf0fc2d7a0ddd27f9d",target:"_blank",rel:"noopener noreferrer"}},[s._v("runtime: make slice growth formula a bit smoother"),t("OutboundLink")],1),s._v("。")]),s._v(" "),t("p",[s._v("大概意思是：")]),s._v(" "),t("p",[s._v("在之前的版本中：对于 "),t("code",[s._v("<1024")]),s._v(" 个元素，增加 "),t("code",[s._v("2")]),s._v(" 倍，对于 "),t("code",[s._v(">=1024")]),s._v(" 个元素，则增加 "),t("code",[s._v("1.25")]),s._v(" 倍。 而现在，使用更平滑的增长因子公式。 在 256 个元素后开始降低增长因子，但要缓慢。")]),s._v(" "),t("p",[s._v("它还给了个表格，写明了不同容量下的增长因子：")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("starting cap")]),s._v(" "),t("th",[s._v("growth factor")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("256")]),s._v(" "),t("td",[s._v("2.0")])]),s._v(" "),t("tr",[t("td",[s._v("512")]),s._v(" "),t("td",[s._v("1.63")])]),s._v(" "),t("tr",[t("td",[s._v("1024")]),s._v(" "),t("td",[s._v("1.44")])]),s._v(" "),t("tr",[t("td",[s._v("2048")]),s._v(" "),t("td",[s._v("1.35")])]),s._v(" "),t("tr",[t("td",[s._v("4096")]),s._v(" "),t("td",[s._v("1.30")])])])]),s._v(" "),t("p",[s._v("从这个表格中，我们可以看到，新版本的切片库容，并不是在容量小于 "),t("code",[s._v("1024")]),s._v(" 的时候严格按照 "),t("code",[s._v("2")]),s._v(" 倍扩容，大于 "),t("code",[s._v("1024")]),s._v(" 的时候也不是严格地按照 "),t("code",[s._v("1.25")]),s._v(" 倍来扩容。")]),s._v(" "),t("h2",{attrs:{id:"growslice-实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#growslice-实现"}},[s._v("#")]),s._v(" growslice 实现")]),s._v(" "),t("p",[s._v("在 go 中，切片扩容的实现是 "),t("code",[s._v("growslice")]),s._v(" 函数，位于 "),t("code",[s._v("runtime/slice.go")]),s._v(" 中。")]),s._v(" "),t("p",[t("code",[s._v("growslice")]),s._v(" 有如下参数：")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("oldPtr")]),s._v(": 旧的切片的底层数组指针。")]),s._v(" "),t("li",[t("code",[s._v("newLen")]),s._v(": 新的切片的长度（"),t("code",[s._v("= oldLen + num")]),s._v("）。")]),s._v(" "),t("li",[t("code",[s._v("oldCap")]),s._v(": 旧的切片的容量。")]),s._v(" "),t("li",[t("code",[s._v("num")]),s._v(": 添加的元素数。")]),s._v(" "),t("li",[t("code",[s._v("et")]),s._v(": 切片的元素类型（也即 "),t("code",[s._v("element type")]),s._v("）。")])]),s._v(" "),t("p",[s._v("返回一个新的切片，这个返回的切片中，底层数组指针指向新分配的内存空间，长度等于 "),t("code",[s._v("oldLen + num")]),s._v("，容量就是底层数组的大小。")]),s._v(" "),t("h3",{attrs:{id:"growslice-实现步骤"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#growslice-实现步骤"}},[s._v("#")]),s._v(" growslice 实现步骤")]),s._v(" "),t("ol",[t("li",[s._v("一些特殊情况判断：如 "),t("code",[s._v("et.size == 0")]),s._v("，切片元素不需要占用空间的情况下，直接返回。")]),s._v(" "),t("li",[s._v("根据 "),t("code",[s._v("newLen")]),s._v(" 计算新的容量，保证新的底层数组至少可以容纳 "),t("code",[s._v("newLen")]),s._v(" 个元素。")]),s._v(" "),t("li",[s._v("计算所需要分配的新的容量所需的内存大小。")]),s._v(" "),t("li",[s._v("分配新的切片底层数组所需要的内存。")]),s._v(" "),t("li",[s._v("将旧切片上的底层数组的数据复制到新的底层数组中。")])]),s._v(" "),t("blockquote",[t("p",[s._v("注意：这个函数只是实现扩容，新增的元素没有在这个函数往切片中追加。")])]),s._v(" "),t("h3",{attrs:{id:"growslice-源码剖析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#growslice-源码剖析"}},[s._v("#")]),s._v(" growslice 源码剖析")]),s._v(" "),t("p",[s._v("说明：")]),s._v(" "),t("ol",[t("li",[s._v("整数有可能会溢出，所以代码里面会判断 "),t("code",[s._v("newLen < 0")]),s._v("。")]),s._v(" "),t("li",[s._v("如果切片的元素是空结构体或者空数组，那么 "),t("code",[s._v("et.size == 0")]),s._v("。")]),s._v(" "),t("li",[s._v("在计算新切片的容量的时候，会根据切片的元素类型大小来做一些优化。")]),s._v(" "),t("li",[s._v("新切片容量所占用的内存大小为 "),t("code",[s._v("capmem")]),s._v("。")]),s._v(" "),t("li",[s._v("新切片所需要的内存分配完成后，会将旧切片的数据复制到新切片中。")]),s._v(" "),t("li",[s._v("最后返回指向新的底层数组的切片，其长度为 "),t("code",[s._v("newLen")]),s._v("，容量为 "),t("code",[s._v("newcap")]),s._v("。")])]),s._v(" "),t("div",{staticClass:"language-go line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-go"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// growtslice 为切片分配新的存储空间。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("growslice")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldPtr unsafe"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Pointer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" et "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("_type"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" slice "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// oldLen 为旧的切片底层数组的长度")]),s._v("\n   oldLen "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" newLen "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" num\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 分配的新的长度不能小于 0（整数溢出的时候会是负数）")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" newLen "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("panic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("errorString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"growslice: len out of range"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果结构或数组类型不包含大小大于零的字段（或元素），则其大小为零。")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//（空数组、空结构体，type b [0]int、type zero struct{}）")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 两个不同的零大小变量在内存中可能具有相同的地址。")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// append 不应创建具有 nil 指针但长度非零的切片。")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 在这种情况下，我们假设 append 不需要保留 oldPtr。")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("unsafe"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("Pointer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v("zerobase"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newcap 是新切片底层数组的容量")]),s._v("\n   newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" oldCap\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 两倍容量")]),s._v("\n   doublecap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" newcap\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" newLen "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" doublecap "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果追加元素之后，新的切片长度比旧切片 2 倍容量还大，")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 则将新的切片的容量设置为跟长度一样")]),s._v("\n      newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newLen\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" threshold "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("256")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" threshold "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 旧的切片容量小于 256 的时候，")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 进行两倍扩容。")]),s._v("\n         newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" doublecap\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// oldCap >= 256")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 检查 0<newcap 以检测溢出并防止无限循环。")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" newLen "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 从小切片的增长 2 倍过渡到大切片的增长 1.25 倍。")]),s._v("\n            newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("threshold"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 当 newcap 计算溢出时，将 newcap 设置为请求的上限。")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newLen\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 计算实际所需要的内存大小")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 是否溢出")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" overflow "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("bool")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// lenmem 表示旧的切片长度所需要的内存大小")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//（lenmem 就是将旧切片数据复制到新切片的时候指定需要复制的内存大小）")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newlenmem 表示新的切片长度所需要的内存大小")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// capmem 表示新的切片容量所需要的内存大小")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" lenmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newlenmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" capmem "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("uintptr")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 根据 et.size 做一些计算上的优化：")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 对于 1，我们不需要任何除法/乘法。")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 对于 goarch.PtrSize，编译器会将除法/乘法优化为移位一个常数。")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 对于 2 的幂，使用可变移位。")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("switch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 比如 []byte，所需内存大小 = size")]),s._v("\n      lenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      newlenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("roundupsize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" maxAlloc\n      newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 比如 []*int，所需内存大小 = size * ptrSize")]),s._v("\n      lenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize\n      newlenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("roundupsize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" maxAlloc"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize\n      newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isPowerOfTwo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 比如 []int64，所需内存大小 = size << shift，也就是 size * 2^shift（2^shift 是 et.size）")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" shift "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("uintptr")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" goarch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PtrSize "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// Mask shift for better code generation.")]),s._v("\n         shift "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sys"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("TrailingZeros64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uint64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("63")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         shift "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sys"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("TrailingZeros32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uint32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      lenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" shift\n      newlenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" shift\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("roundupsize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" shift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("maxAlloc "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" shift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" shift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" shift\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 没得优化，直接使用乘法了")]),s._v("\n      lenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size\n      newlenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size\n      capmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" math"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("MulUintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("roundupsize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      newcap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 检查是否溢出，以及是否超过最大可分配内存")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" capmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" maxAlloc "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("panic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("errorString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"growslice: len out of range"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 分配实际所需要的内存")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" p unsafe"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Pointer\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ptrdata "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 不包含指针")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 分配 capmem 大小的内存，不清零")]),s._v("\n      p "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("mallocgc")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 这里只清空从 add(p, newlenmem) 开始大小为 capmem-newlenmem 的内存，")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 也就是前面的 newlenmem 长度不清空。")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 因为最后的 capmem-newlenmem 这块内存，实际上是额外分配的容量。")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 前面的那部分会被旧切片的数据以及新追加的数据覆盖。")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("memclrNoHeapPointers")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("add")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newlenmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" capmem"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("newlenmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 分配 capmem 大小的内存，需要进行清零")]),s._v("\n      p "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("mallocgc")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("capmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" lenmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" writeBarrier"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("enabled "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// Only shade the pointers in oldPtr since we know the destination slice p")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// only contains nil pointers because it has been cleared during alloc.")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bulkBarrierPreWriteSrcOnly")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uintptr")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldPtr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lenmem"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("et"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ptrdata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 旧切片数据复制到新切片中，复制的内容大小为 lenmem")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//（从 oldPtr 复制到 p）")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("memmove")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldPtr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lenmem"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" slice"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newLen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newcap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br"),t("span",{staticClass:"line-number"},[s._v("84")]),t("br"),t("span",{staticClass:"line-number"},[s._v("85")]),t("br"),t("span",{staticClass:"line-number"},[s._v("86")]),t("br"),t("span",{staticClass:"line-number"},[s._v("87")]),t("br"),t("span",{staticClass:"line-number"},[s._v("88")]),t("br"),t("span",{staticClass:"line-number"},[s._v("89")]),t("br"),t("span",{staticClass:"line-number"},[s._v("90")]),t("br"),t("span",{staticClass:"line-number"},[s._v("91")]),t("br"),t("span",{staticClass:"line-number"},[s._v("92")]),t("br"),t("span",{staticClass:"line-number"},[s._v("93")]),t("br"),t("span",{staticClass:"line-number"},[s._v("94")]),t("br"),t("span",{staticClass:"line-number"},[s._v("95")]),t("br"),t("span",{staticClass:"line-number"},[s._v("96")]),t("br"),t("span",{staticClass:"line-number"},[s._v("97")]),t("br"),t("span",{staticClass:"line-number"},[s._v("98")]),t("br"),t("span",{staticClass:"line-number"},[s._v("99")]),t("br"),t("span",{staticClass:"line-number"},[s._v("100")]),t("br"),t("span",{staticClass:"line-number"},[s._v("101")]),t("br"),t("span",{staticClass:"line-number"},[s._v("102")]),t("br"),t("span",{staticClass:"line-number"},[s._v("103")]),t("br"),t("span",{staticClass:"line-number"},[s._v("104")]),t("br"),t("span",{staticClass:"line-number"},[s._v("105")]),t("br"),t("span",{staticClass:"line-number"},[s._v("106")]),t("br"),t("span",{staticClass:"line-number"},[s._v("107")]),t("br"),t("span",{staticClass:"line-number"},[s._v("108")]),t("br"),t("span",{staticClass:"line-number"},[s._v("109")]),t("br"),t("span",{staticClass:"line-number"},[s._v("110")]),t("br"),t("span",{staticClass:"line-number"},[s._v("111")]),t("br"),t("span",{staticClass:"line-number"},[s._v("112")]),t("br"),t("span",{staticClass:"line-number"},[s._v("113")]),t("br"),t("span",{staticClass:"line-number"},[s._v("114")]),t("br"),t("span",{staticClass:"line-number"},[s._v("115")]),t("br"),t("span",{staticClass:"line-number"},[s._v("116")]),t("br"),t("span",{staticClass:"line-number"},[s._v("117")]),t("br"),t("span",{staticClass:"line-number"},[s._v("118")]),t("br"),t("span",{staticClass:"line-number"},[s._v("119")]),t("br"),t("span",{staticClass:"line-number"},[s._v("120")]),t("br"),t("span",{staticClass:"line-number"},[s._v("121")]),t("br"),t("span",{staticClass:"line-number"},[s._v("122")]),t("br"),t("span",{staticClass:"line-number"},[s._v("123")]),t("br"),t("span",{staticClass:"line-number"},[s._v("124")]),t("br"),t("span",{staticClass:"line-number"},[s._v("125")]),t("br"),t("span",{staticClass:"line-number"},[s._v("126")]),t("br"),t("span",{staticClass:"line-number"},[s._v("127")]),t("br")])]),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结")]),s._v(" "),t("p",[s._v("go 的切片在容量较小的情况下，确实会进行 "),t("code",[s._v("2")]),s._v(" 倍扩容，但是随着容量的增长，扩容的增长因子会逐渐降低。 新版本的 "),t("code",[s._v("growslice")]),s._v(" 实现中，只有容量小于 "),t("code",[s._v("256")]),s._v(" 的时候才会进行 "),t("code",[s._v("2")]),s._v(" 倍扩容， 然后随着容量的增长，扩容的因子会逐渐降低（但并不是直接降到 "),t("code",[s._v("1.25")]),s._v("，而是一个相对缓慢的下降）。")])])}),[],!1,null,null,null);t.default=e.exports}}]);